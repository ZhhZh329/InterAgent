import os
import asyncio
import logging
import subprocess
from typing import Dict, List, Optional
from pathlib import Path
from datetime import datetime
from src.utils.openai_client import get_client
from src.InterAgent.coding_agent import CodingAgent
from src.mle_bench.evaluator_agent import MLEBenchEvaluator


class InterAgent:
    """ä¸»è¦çš„ç ”ç©¶ä»£ç†ï¼Œè´Ÿè´£åè°ƒæ•´ä¸ªç ”ç©¶ä»»åŠ¡æµç¨‹"""

    def __init__(self, model_name: Optional[str] = None, device_info: Optional[Dict] = None):
        self.client = get_client(model_name)
        self.coding_agent = CodingAgent(model_name)
        self.logger = logging.getLogger(__name__)
        self.workspace_root = Path("workspaces")
        self.device_info = device_info or {'device_type': 'cpu', 'device_name': 'CPU'}

        # åˆå§‹åŒ–è¯„ä¼°å™¨å­—å…¸
        self.evaluators = {
            'mlebench': MLEBenchEvaluator()
        }
    
    async def run_research_task(
        self,
        research_topic: str,
        research_goal: str,
        dataset_path: str,
        benchmark_name: str = "mlebench",
        dataset_name: str = "unknown",
        debug: bool = False
    ) -> Dict[str, str]:
        """
        ä¸»å…¥å£å‡½æ•°ï¼Œæ‰§è¡Œç ”ç©¶ä»»åŠ¡
        
        Args:
            research_topic: ç ”ç©¶ä¸»é¢˜æè¿°
            research_goal: ç ”ç©¶ç›®æ ‡
            dataset_path: æ•°æ®é›†è·¯å¾„
            benchmark_name: benchmarkåç§°
            dataset_name: æ•°æ®é›†åç§°
            debug: æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼
        
        Returns:
            DictåŒ…å«ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        # åˆ›å»ºå·¥ä½œç›®å½•
        workspace_dir = self._create_workspace(benchmark_name, dataset_name)
        
        self.logger.info("å¼€å§‹æ‰§è¡Œç ”ç©¶ä»»åŠ¡")
        self.logger.info(f"ç ”ç©¶ä¸»é¢˜: {research_topic}")
        self.logger.info(f"ç ”ç©¶ç›®æ ‡: {research_goal}")
        self.logger.info(f"æ•°æ®é›†è·¯å¾„: {dataset_path}")
        self.logger.info(f"å·¥ä½œç›®å½•: {workspace_dir}")
        
        try:
            # é¦–å…ˆæ¢æµ‹æ–‡ä»¶ç»“æ„
            structure_info = await self.file_structure_probing(dataset_path)
            self.logger.info(f"æ–‡ä»¶ç»“æ„åˆ†æå®Œæˆ: {structure_info['status']}")
            
            # ç”Ÿæˆæ•°æ®åŠ è½½ä»£ç 
            data_loader_result = await self._generate_data_loader(
                structure_info, dataset_path, workspace_dir
            )
            self.logger.info(f"æ•°æ®åŠ è½½ä»£ç ç”Ÿæˆ: {data_loader_result['status']}")
            
            # æ‰§è¡Œæ•°æ®åŠ è½½æµ‹è¯•ï¼ˆæ— è®ºdebugæ¨¡å¼å¦‚ä½•éƒ½ä¼šæ‰§è¡Œï¼‰
            test_result = await self._test_data_loader(workspace_dir)
            self.logger.info(f"æ•°æ®åŠ è½½æµ‹è¯•: {test_result['status']}")
            
            # å¦‚æœæ•°æ®åŠ è½½å¤±è´¥ï¼Œå°è¯•debugä¿®å¤
            if test_result['status'] == 'error' and test_result.get('detailed_error'):
                self.logger.info("æ•°æ®åŠ è½½å¤±è´¥ï¼Œå°è¯•è‡ªåŠ¨ä¿®å¤...")
                debug_result = await self._debug_data_loader_with_retry(
                    workspace_dir, test_result['detailed_error']
                )
                if debug_result['status'] == 'success':
                    # é‡æ–°æµ‹è¯•ä¿®å¤åçš„ä»£ç 
                    test_result = await self._test_data_loader(workspace_dir)
                    self.logger.info(f"ä¿®å¤åæ•°æ®åŠ è½½æµ‹è¯•: {test_result['status']}")
            
            # åˆæ­¥åˆ†æï¼šåŸºäºæ•°æ®ç»“æ„å’Œç ”ç©¶ä»»åŠ¡è¿›è¡Œåˆ†æ
            init_analysis_result = None
            if test_result.get('data_structure_info'):
                init_analysis_result = await self.init_analyzing(
                    research_topic=research_topic,
                    research_goal=research_goal,
                    dataset_path=dataset_path,
                    data_structure_info=test_result['data_structure_info'],
                    structure_analysis=structure_info.get('analysis_result', {})
                )
                self.logger.info(f"åˆæ­¥åˆ†æ: {init_analysis_result['status']}")
            
            # ç”Ÿæˆç ”ç©¶ä»£ç ï¼šåŸºäºåˆæ­¥åˆ†æç»“æœç”Ÿæˆresearch.py
            research_code_result = None
            if init_analysis_result and init_analysis_result['status'] == 'success':
                # è·å–æäº¤æ–‡ä»¶å
                submission_file_name = self._get_submission_file_name(structure_info, benchmark_name)
                
                research_code_result = await self._generate_research_code(
                    research_topic=research_topic,
                    research_goal=research_goal,
                    init_analysis=init_analysis_result['analysis_content'],
                    data_structure_info=test_result['data_structure_info'],
                    submission_file_name=submission_file_name,
                    workspace_dir=workspace_dir
                )
                self.logger.info(f"ç ”ç©¶ä»£ç ç”Ÿæˆ: {research_code_result['status']}")
                
                # æ— è®ºç”ŸæˆæˆåŠŸä¸å¦ï¼Œéƒ½è¦æµ‹è¯•ç ”ç©¶ä»£ç æ‰§è¡Œ
                if research_code_result['status'] == 'success':
                    # æµ‹è¯•ç”Ÿæˆçš„ç ”ç©¶ä»£ç 
                    research_test_result = await self._test_research_code(workspace_dir)
                    self.logger.info(f"ç ”ç©¶ä»£ç æµ‹è¯•: {research_test_result['status']}")
                    
                    # å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œå¯åŠ¨debugå¾ªç¯
                    if research_test_result['status'] == 'error' and research_test_result.get('detailed_error'):
                        self.logger.info("ç ”ç©¶ä»£ç æ‰§è¡Œå¤±è´¥ï¼Œå¯åŠ¨è‡ªåŠ¨debugå¾ªç¯...")
                        max_retries = 3
                        retry_count = 0
                        install_attempts = 0  # ä¾èµ–å®‰è£…å°è¯•æ¬¡æ•°
                        max_install_attempts = 3

                        while retry_count < max_retries and research_test_result['status'] == 'error':
                            # æ£€æŸ¥æ˜¯å¦æ˜¯ModuleNotFoundError
                            error_message = research_test_result.get('detailed_error', '')
                            is_module_error = 'ModuleNotFoundError' in error_message or 'No module named' in error_message

                            if is_module_error and install_attempts < max_install_attempts:
                                # å°è¯•å®‰è£…ç¼ºå¤±çš„åŒ…
                                install_attempts += 1
                                self.logger.info(f"æ£€æµ‹åˆ°ModuleNotFoundErrorï¼Œå°è¯•è‡ªåŠ¨å®‰è£…ä¾èµ– ({install_attempts}/{max_install_attempts})...")
                                self.logger.error("=" * 80)
                                self.logger.error("ç¼ºå¤±ä¾èµ–é”™è¯¯:")
                                self.logger.error(error_message)
                                self.logger.error("=" * 80)

                                # è°ƒç”¨CodingAgentå®‰è£…ä¾èµ–
                                install_result = await self.coding_agent.install_missing_package(
                                    error_message=error_message,
                                    project_root=str(self.workspace_root.parent)  # é¡¹ç›®æ ¹ç›®å½•
                                )

                                if install_result['status'] == 'success':
                                    self.logger.info(f"æˆåŠŸå®‰è£…: {install_result.get('package_name')}")
                                    # ç›´æ¥é‡æ–°æµ‹è¯•ï¼Œä¸è®¡å…¥debugæ¬¡æ•°
                                    research_test_result = await self._test_research_code(workspace_dir)
                                    self.logger.info(f"å®‰è£…ä¾èµ–åé‡æ–°æµ‹è¯•: {research_test_result['status']}")

                                    if research_test_result['status'] == 'success':
                                        self.logger.info("å®‰è£…ä¾èµ–åä»£ç æ‰§è¡ŒæˆåŠŸï¼")
                                        break
                                else:
                                    self.logger.error(f"ä¾èµ–å®‰è£…å¤±è´¥: {install_result.get('error')}")
                                    # å¦‚æœè¾¾åˆ°æœ€å¤§å®‰è£…å°è¯•æ¬¡æ•°ï¼Œè¿›å…¥æ­£å¸¸debugæµç¨‹
                                    if install_attempts >= max_install_attempts:
                                        self.logger.error(f"å·²è¾¾åˆ°æœ€å¤§ä¾èµ–å®‰è£…å°è¯•æ¬¡æ•°({max_install_attempts})ï¼Œè¿›å…¥ä»£ç è°ƒè¯•æµç¨‹")

                            # ä¸æ˜¯ä¾èµ–é—®é¢˜æˆ–å·²ç»å°è¯•å®‰è£…å¤šæ¬¡ï¼Œè¿›å…¥æ­£å¸¸debugæµç¨‹
                            if not is_module_error or install_attempts >= max_install_attempts:
                                retry_count += 1
                                self.logger.info(f"Debugå°è¯• {retry_count}/{max_retries}...")
                                # æ‰“å°è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                                self.logger.error("=" * 80)
                                self.logger.error("é”™è¯¯è¯¦æƒ…:")
                                self.logger.error(error_message)
                                self.logger.error("=" * 80)

                                debug_result = await self._debug_research_code_with_retry(
                                    workspace_dir, research_test_result['detailed_error']
                                )

                                if debug_result['status'] == 'success':
                                    # é‡æ–°æµ‹è¯•ä¿®å¤åçš„ä»£ç 
                                    research_test_result = await self._test_research_code(workspace_dir)
                                    self.logger.info(f"ä¿®å¤åç ”ç©¶ä»£ç æµ‹è¯•: {research_test_result['status']}")

                                    if research_test_result['status'] == 'success':
                                        self.logger.info("ç ”ç©¶ä»£ç debugæˆåŠŸï¼Œä»£ç å¯æ­£å¸¸è¿è¡Œ")
                                        break
                                else:
                                    self.logger.error(f"Debugå¤±è´¥: {debug_result.get('message', '')}")

                        if research_test_result['status'] == 'error':
                            self.logger.error(f"ç»è¿‡{max_retries}æ¬¡debugå°è¯•å’Œ{install_attempts}æ¬¡ä¾èµ–å®‰è£…åï¼Œç ”ç©¶ä»£ç ä»ç„¶å¤±è´¥")

                    # å¦‚æœå°æ ·æœ¬æµ‹è¯•æˆåŠŸï¼Œè¿è¡Œå®Œæ•´æ•°æ®é›†
                    full_run_result = None
                    if research_test_result['status'] == 'success':
                        self.logger.info("=" * 80)
                        self.logger.info("å°æ ·æœ¬æµ‹è¯•é€šè¿‡ï¼Œå¼€å§‹è¿è¡Œå®Œæ•´æ•°æ®é›†...")
                        self.logger.info("=" * 80)
                        full_run_result = await self._run_full_research_code(workspace_dir)
                        self.logger.info(f"å®Œæ•´æ•°æ®é›†è¿è¡Œ: {full_run_result['status']}")

                        if full_run_result['status'] == 'success':
                            self.logger.info("å®Œæ•´æ•°æ®é›†è®­ç»ƒæˆåŠŸï¼")
                            self.logger.info(f"ç”Ÿæˆçš„submissionæ–‡ä»¶: {full_run_result.get('submission_files', [])}")

                            # è¯„ä¼°ç»“æœ
                            evaluation_result = await self._evaluate_submission(
                                workspace_dir,
                                dataset_name,
                                benchmark_name
                            )
                            full_run_result['evaluation'] = evaluation_result

                            if evaluation_result['status'] == 'success':
                                self.logger.info("=" * 80)
                                self.logger.info("=== è¯„ä¼°ç»“æœ ===")
                                self.logger.info(f"åˆ†æ•°: {evaluation_result.get('score', 'N/A')}")
                                self.logger.info(f"é‡‘ç‰Œ: {'æ˜¯' if evaluation_result.get('gold_medal') else 'å¦'}")
                                self.logger.info(f"é“¶ç‰Œ: {'æ˜¯' if evaluation_result.get('silver_medal') else 'å¦'}")
                                self.logger.info(f"é“œç‰Œ: {'æ˜¯' if evaluation_result.get('bronze_medal') else 'å¦'}")
                                self.logger.info(f"è¶…è¿‡ä¸­ä½æ•°: {'æ˜¯' if evaluation_result.get('above_median') else 'å¦'}")
                                self.logger.info(f"æäº¤æœ‰æ•ˆ: {'æ˜¯' if evaluation_result.get('valid_submission') else 'å¦'}")
                                self.logger.info(evaluation_result.get('message', ''))
                                self.logger.info("=" * 80)
                            else:
                                self.logger.error("=" * 80)
                                self.logger.error("=== è¯„ä¼°å¤±è´¥ ===")
                                self.logger.error(f"é”™è¯¯: {evaluation_result.get('error_message', 'unknown')}")
                                self.logger.error(f"å¤±è´¥ç±»å‹: {evaluation_result.get('failure_type', 'unknown')}")
                                self.logger.error("=" * 80)

                                # æ™ºèƒ½é‡è¯•é€»è¾‘
                                max_retry_attempts = 3  # æœ€å¤šé‡è¯•3æ¬¡ï¼ˆåŒ…æ‹¬é‡æ–°ç”Ÿæˆå’Œé‡æ–°è¯„ä¼°ï¼‰
                                retry_count = 0
                                regeneration_count = 0

                                while retry_count < max_retry_attempts and evaluation_result['status'] == 'error':
                                    retry_count += 1
                                    requires_regeneration = evaluation_result.get('requires_code_regeneration', False)

                                    self.logger.info(f"DEBUG: evaluation_result keys: {evaluation_result.keys()}")
                                    self.logger.info(f"DEBUG: requires_code_regeneration = {requires_regeneration}")
                                    self.logger.info(f"DEBUG: failure_type = {evaluation_result.get('failure_type')}")

                                    if requires_regeneration:
                                        # éœ€è¦é‡æ–°ç”Ÿæˆä»£ç 
                                        regeneration_count += 1
                                        self.logger.info("=" * 80)
                                        self.logger.info(f"=== ç¬¬ {regeneration_count} æ¬¡é‡æ–°ç”Ÿæˆresearch.pyï¼ˆåŸå› ï¼š{evaluation_result.get('failure_type')}ï¼‰===")
                                        self.logger.info("=" * 80)

                                        # å®Œå…¨é‡æ–°ç”Ÿæˆresearch.py
                                        research_code_result = await self._generate_research_code(
                                            research_topic=research_topic,
                                            research_goal=research_goal,
                                            init_analysis=init_analysis_result['analysis_content'],
                                            data_structure_info=test_result['data_structure_info'],
                                            submission_file_name=submission_file_name,
                                            workspace_dir=workspace_dir
                                        )

                                        if research_code_result['status'] == 'success':
                                            # æµ‹è¯•æ–°ä»£ç 
                                            research_test_result = await self._test_research_code(workspace_dir)

                                            if research_test_result['status'] == 'success':
                                                # è¿è¡Œå®Œæ•´æ•°æ®é›†
                                                full_run_result = await self._run_full_research_code(workspace_dir)

                                                if full_run_result['status'] == 'success':
                                                    # é‡æ–°è¯„ä¼°
                                                    evaluation_result = await self._evaluate_submission(
                                                        workspace_dir,
                                                        dataset_name,
                                                        benchmark_name
                                                    )
                                                    full_run_result['evaluation'] = evaluation_result

                                                    if evaluation_result['status'] == 'success':
                                                        self.logger.info("=" * 80)
                                                        self.logger.info(f"=== ç¬¬ {regeneration_count} æ¬¡é‡æ–°ç”Ÿæˆåè¯„ä¼°æˆåŠŸ ===")
                                                        self.logger.info(f"åˆ†æ•°: {evaluation_result.get('score', 'N/A')}")
                                                        self.logger.info(evaluation_result.get('message', ''))
                                                        self.logger.info("=" * 80)
                                                        break
                                                    else:
                                                        self.logger.error(f"ç¬¬ {regeneration_count} æ¬¡é‡æ–°ç”Ÿæˆåè¯„ä¼°ä»ç„¶å¤±è´¥")
                                                else:
                                                    self.logger.error(f"ç¬¬ {regeneration_count} æ¬¡é‡æ–°ç”Ÿæˆçš„ä»£ç å®Œæ•´è¿è¡Œå¤±è´¥")
                                                    break
                                            else:
                                                self.logger.error(f"ç¬¬ {regeneration_count} æ¬¡é‡æ–°ç”Ÿæˆçš„ä»£ç æµ‹è¯•å¤±è´¥")
                                                break
                                        else:
                                            self.logger.error(f"ç¬¬ {regeneration_count} æ¬¡é‡æ–°ç”Ÿæˆresearch.pyå¤±è´¥")
                                            break
                                    else:
                                        # ä¸éœ€è¦é‡æ–°ç”Ÿæˆä»£ç ï¼Œåªéœ€é‡æ–°è¯„ä¼°ï¼ˆå¯èƒ½æ˜¯ä¸´æ—¶é—®é¢˜æˆ–æ–‡ä»¶æŸ¥æ‰¾é—®é¢˜ï¼‰
                                        self.logger.info("=" * 80)
                                        self.logger.info(f"=== ç¬¬ {retry_count} æ¬¡é‡æ–°è¯„ä¼°ï¼ˆä¸é‡æ–°ç”Ÿæˆä»£ç ï¼‰===")
                                        self.logger.info("=" * 80)

                                        evaluation_result = await self._evaluate_submission(
                                            workspace_dir,
                                            dataset_name,
                                            benchmark_name
                                        )
                                        full_run_result['evaluation'] = evaluation_result

                                        if evaluation_result['status'] == 'success':
                                            self.logger.info("=" * 80)
                                            self.logger.info(f"=== é‡æ–°è¯„ä¼°æˆåŠŸ ===")
                                            self.logger.info(f"åˆ†æ•°: {evaluation_result.get('score', 'N/A')}")
                                            self.logger.info(evaluation_result.get('message', ''))
                                            self.logger.info("=" * 80)
                                            break
                                        else:
                                            self.logger.error(f"é‡æ–°è¯„ä¼°ä»ç„¶å¤±è´¥")
                                            # å¦‚æœé‡æ–°è¯„ä¼°è¿˜æ˜¯å¤±è´¥ä¸”ä»ç„¶ä¸éœ€è¦é‡æ–°ç”Ÿæˆï¼Œå¯èƒ½æ˜¯å…¶ä»–é—®é¢˜
                                            if not evaluation_result.get('requires_code_regeneration', False):
                                                self.logger.error("è¯„ä¼°å™¨æŒç»­å¤±è´¥ä¸”ä¸éœ€è¦é‡æ–°ç”Ÿæˆä»£ç ï¼Œå¯èƒ½æ˜¯é…ç½®æˆ–ç¯å¢ƒé—®é¢˜")
                                                break

                                if retry_count >= max_retry_attempts and evaluation_result['status'] == 'error':
                                    self.logger.error(f"å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retry_attempts})ï¼Œè¯„ä¼°ä»ç„¶å¤±è´¥")

                                # æ›´æ–°research_code_resultä»¥åŒ…å«é‡è¯•ä¿¡æ¯
                                research_code_result['regeneration_count'] = regeneration_count
                                research_code_result['total_retry_count'] = retry_count
                        else:
                            # å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥ï¼Œå¯åŠ¨é‡è¯•å¾ªç¯
                            self.logger.error(f"å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥: {full_run_result.get('message', '')}")

                            max_full_run_retries = 3
                            full_run_retry_count = 0
                            full_regeneration_count = 0

                            while full_run_retry_count < max_full_run_retries and full_run_result['status'] == 'error':
                                full_run_retry_count += 1
                                full_regeneration_count += 1

                                # åˆ†æå¤±è´¥åŸå› 
                                failure_message = full_run_result.get('message', '')
                                error_output = full_run_result.get('stderr', '') + '\n' + full_run_result.get('stdout', '')

                                # æ„å»ºä¼˜åŒ–æç¤º
                                optimization_hint = ""
                                if 'è¶…æ—¶' in failure_message or 'timeout' in failure_message.lower():
                                    optimization_hint = """
ä»£ç æ‰§è¡Œè¶…æ—¶ï¼ˆ2å°æ—¶é™åˆ¶ï¼‰ã€‚è¯·ä¼˜åŒ–ä»£ç ä»¥æé«˜è¿è¡Œé€Ÿåº¦ï¼š
1. å‡å°‘ç‰¹å¾æ•°é‡ï¼ˆå¦‚TF-IDFçš„max_featuresä»5000é™åˆ°1000-2000ï¼‰
2. ä½¿ç”¨æ›´ç®€å•çš„æ¨¡å‹ï¼ˆå¦‚LogisticRegressionè€Œéå¤æ‚çš„é›†æˆæ¨¡å‹ï¼‰
3. å‡å°‘è®­ç»ƒæ•°æ®é‡ï¼ˆå¦‚ä½¿ç”¨stratified samplingå–å­é›†ï¼‰
4. ç§»é™¤è€—æ—¶çš„ç‰¹å¾å·¥ç¨‹æ­¥éª¤
5. é¿å…ä½¿ç”¨å¾ªç¯éå†æ•°æ®ï¼Œä½¿ç”¨å‘é‡åŒ–æ“ä½œ
6. ç¡®ä¿ä½¿ç”¨n_jobs=-1ç­‰å¹¶è¡Œå‚æ•°åŠ é€Ÿè®­ç»ƒ
"""
                                elif 'memory' in failure_message.lower() or 'oom' in failure_message.lower():
                                    optimization_hint = """
å†…å­˜ä¸è¶³é”™è¯¯ã€‚è¯·ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼š
1. å‡å°‘TF-IDFç‰¹å¾æ•°é‡ï¼ˆmax_featuresé™ä½åˆ°1000ä»¥ä¸‹ï¼‰
2. ä½¿ç”¨sparse matrixè€Œédense matrix
3. åˆ†æ‰¹å¤„ç†æ•°æ®è€Œéä¸€æ¬¡æ€§åŠ è½½
4. ä½¿ç”¨å†…å­˜é«˜æ•ˆçš„æ¨¡å‹ï¼ˆLinearSVC, SGDClassifierç­‰ï¼‰
5. åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„ä¸­é—´å˜é‡
"""
                                else:
                                    optimization_hint = f"""
å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š
{error_output[-1000:] if len(error_output) > 1000 else error_output}

è¯·åˆ†æé”™è¯¯å¹¶ä¼˜åŒ–ä»£ç ï¼Œç¡®ä¿èƒ½åœ¨2å°æ—¶å†…å®Œæˆè®­ç»ƒã€‚
"""

                                self.logger.info("=" * 80)
                                self.logger.info(f"=== ç¬¬ {full_regeneration_count} æ¬¡é‡æ–°ç”Ÿæˆresearch.pyï¼ˆå®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥ï¼‰===")
                                self.logger.info(f"å¤±è´¥åŸå› : {failure_message}")
                                self.logger.info("=" * 80)

                                # é‡æ–°ç”Ÿæˆä»£ç ï¼Œå¸¦ä¸Šä¼˜åŒ–æç¤º
                                optimized_init_analysis = init_analysis_result['analysis_content'] + "\n\n**é‡è¦ä¼˜åŒ–è¦æ±‚**ï¼š" + optimization_hint

                                research_code_result = await self._generate_research_code(
                                    research_topic=research_topic,
                                    research_goal=research_goal,
                                    init_analysis=optimized_init_analysis,
                                    data_structure_info=test_result['data_structure_info'],
                                    submission_file_name=submission_file_name,
                                    workspace_dir=workspace_dir
                                )

                                if research_code_result['status'] == 'success':
                                    # æµ‹è¯•æ–°ä»£ç 
                                    research_test_result = await self._test_research_code(workspace_dir)

                                    if research_test_result['status'] == 'success':
                                        # é‡æ–°è¿è¡Œå®Œæ•´æ•°æ®é›†
                                        full_run_result = await self._run_full_research_code(workspace_dir)

                                        if full_run_result['status'] == 'success':
                                            self.logger.info("=" * 80)
                                            self.logger.info(f"=== ç¬¬ {full_regeneration_count} æ¬¡ä¼˜åŒ–åå®Œæ•´è¿è¡ŒæˆåŠŸ ===")
                                            self.logger.info("=" * 80)

                                            # è¯„ä¼°ç»“æœ
                                            evaluation_result = await self._evaluate_submission(
                                                workspace_dir,
                                                dataset_name,
                                                benchmark_name
                                            )
                                            full_run_result['evaluation'] = evaluation_result

                                            if evaluation_result['status'] == 'success':
                                                self.logger.info("=" * 80)
                                                self.logger.info("=== è¯„ä¼°ç»“æœ ===")
                                                self.logger.info(f"åˆ†æ•°: {evaluation_result.get('score', 'N/A')}")
                                                self.logger.info(f"é‡‘ç‰Œ: {'æ˜¯' if evaluation_result.get('gold_medal') else 'å¦'}")
                                                self.logger.info(f"é“¶ç‰Œ: {'æ˜¯' if evaluation_result.get('silver_medal') else 'å¦'}")
                                                self.logger.info(f"é“œç‰Œ: {'æ˜¯' if evaluation_result.get('bronze_medal') else 'å¦'}")
                                                self.logger.info(f"è¶…è¿‡ä¸­ä½æ•°: {'æ˜¯' if evaluation_result.get('above_median') else 'å¦'}")
                                                self.logger.info(f"æäº¤æœ‰æ•ˆ: {'æ˜¯' if evaluation_result.get('valid_submission') else 'å¦'}")
                                                self.logger.info(evaluation_result.get('message', ''))
                                                self.logger.info("=" * 80)
                                            break
                                        else:
                                            self.logger.error(f"ç¬¬ {full_regeneration_count} æ¬¡ä¼˜åŒ–åå®Œæ•´è¿è¡Œä»ç„¶å¤±è´¥: {full_run_result.get('message', '')}")
                                    else:
                                        self.logger.error(f"ç¬¬ {full_regeneration_count} æ¬¡ä¼˜åŒ–åçš„ä»£ç æµ‹è¯•å¤±è´¥")
                                        # æµ‹è¯•å¤±è´¥ä¹Ÿè¦ç»§ç»­é‡è¯•ï¼Œä¸è¦break
                                else:
                                    self.logger.error(f"ç¬¬ {full_regeneration_count} æ¬¡é‡æ–°ç”Ÿæˆresearch.pyå¤±è´¥")
                                    break

                            if full_run_retry_count >= max_full_run_retries and full_run_result['status'] == 'error':
                                self.logger.error(f"å·²è¾¾åˆ°æœ€å¤§å®Œæ•´è¿è¡Œé‡è¯•æ¬¡æ•° ({max_full_run_retries})ï¼Œå®Œæ•´è¿è¡Œä»ç„¶å¤±è´¥")

                    # æ›´æ–°research_code_resultä»¥åŒ…å«æµ‹è¯•ç»“æœå’Œå®Œæ•´è¿è¡Œç»“æœ
                    research_code_result['test_result'] = research_test_result
                    research_code_result['full_run_result'] = full_run_result
                    if research_test_result['status'] == 'success':
                        if full_run_result and full_run_result['status'] == 'success':
                            research_code_result['status'] = 'success'
                            research_code_result['message'] = 'ç ”ç©¶ä»£ç ç”Ÿæˆã€æµ‹è¯•å’Œå®Œæ•´è¿è¡Œå…¨éƒ¨æˆåŠŸ'
                        else:
                            research_code_result['status'] = 'partial_success'
                            research_code_result['message'] = 'ç ”ç©¶ä»£ç æµ‹è¯•æˆåŠŸä½†å®Œæ•´è¿è¡Œå¤±è´¥'
                    else:
                        research_code_result['status'] = 'error'
                        research_code_result['message'] = 'ç ”ç©¶ä»£ç ç”ŸæˆæˆåŠŸä½†æ‰§è¡Œå¤±è´¥'
            
            return {
                "status": "success",
                "workspace_dir": str(workspace_dir),
                "research_topic": research_topic,
                "research_goal": research_goal,
                "dataset_path": dataset_path,
                "structure_info": structure_info,
                "data_loader_result": data_loader_result,
                "test_result": test_result,  # æ›¿æ¢debug_result
                "init_analysis_result": init_analysis_result,  # æ–°å¢åˆæ­¥åˆ†æç»“æœ
                "research_code_result": research_code_result,  # æ–°å¢ç ”ç©¶ä»£ç ç»“æœ
                "message": "ç ”ç©¶ä»»åŠ¡å¯åŠ¨æˆåŠŸ"
            }
            
        except Exception as e:
            self.logger.error(f"ç ”ç©¶ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"ç ”ç©¶ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"
            }
    
    async def file_structure_probing(self, dataset_path: str) -> Dict[str, str]:
        """
        æ–‡ä»¶ç»“æ„æ¢æµ‹ï¼Œåˆ†ææ•°æ®é›†ç»“æ„å¹¶åˆ¤æ–­æ–‡ä»¶åŠ è½½éœ€æ±‚
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„
        
        Returns:
            DictåŒ…å«ç»“æ„åˆ†æç»“æœ
        """
        self.logger.info(f"å¼€å§‹æ¢æµ‹æ–‡ä»¶ç»“æ„: {dataset_path}")
        
        try:
            # è·å–æ•°æ®é›†ç›®å½•ç»“æ„ä¿¡æ¯
            structure_summary = self._get_directory_structure(dataset_path)
            
            # æ„å»ºåˆ†æprompt
            prompt = self._build_structure_analysis_prompt(structure_summary)
            
            # è°ƒç”¨LLMåˆ†ææ–‡ä»¶ç»“æ„
            messages = [{"role": "user", "content": prompt}]
            response = await self.client.chat(messages, max_tokens=2000)
            
            # è°ƒè¯•ï¼šè®°å½•LLMå“åº”
            self.logger.info(f"LLMæ–‡ä»¶ç»“æ„åˆ†æå“åº”: {response}")
            
            # è§£æLLMå“åº”
            analysis_result = self._parse_structure_analysis(response)
            
            self.logger.info("æ–‡ä»¶ç»“æ„æ¢æµ‹å®Œæˆ")
            
            return {
                "status": "success",
                "dataset_path": dataset_path,
                "structure_summary": structure_summary,
                "analysis_result": analysis_result,
                "message": "æ–‡ä»¶ç»“æ„åˆ†æå®Œæˆ"
            }
            
        except Exception as e:
            self.logger.error(f"æ–‡ä»¶ç»“æ„æ¢æµ‹å¤±è´¥: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"æ–‡ä»¶ç»“æ„æ¢æµ‹å¤±è´¥: {str(e)}"
            }
    
    def _get_directory_structure(self, dataset_path: str, max_files_per_dir: int = 10) -> str:
        """
        è·å–ç›®å½•ç»“æ„æ‘˜è¦ï¼Œé€’å½’éå†æ‰€æœ‰ç›®å½•å±‚çº§ï¼Œæ˜¾ç¤ºå®Œæ•´è·¯å¾„å¸®åŠ©LLMç†è§£æ–‡ä»¶æ ¼å¼
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„
            max_files_per_dir: æ¯ä¸ªç›®å½•æœ€å¤§æ–‡ä»¶æ•°é™åˆ¶
        
        Returns:
            ç›®å½•ç»“æ„çš„å­—ç¬¦ä¸²æè¿°
        """
        path = Path(dataset_path)
        if not path.exists():
            return f"è·¯å¾„ä¸å­˜åœ¨: {dataset_path}"
        
        structure_lines = []
        structure_lines.append(f"æ•°æ®é›†æ ¹ç›®å½•: {dataset_path}")
        structure_lines.append("")
        structure_lines.append("æ–‡ä»¶ç»“æ„åˆ†æ:")
        
        def _get_relative_path(file_path: Path) -> str:
            """è·å–ç›¸å¯¹äºæ•°æ®é›†æ ¹ç›®å½•çš„è·¯å¾„"""
            try:
                return f"./{file_path.relative_to(path)}"
            except ValueError:
                return str(file_path)
        
        def _explore_directory(dir_path: Path, level: int = 0, max_level: int = 4):
            """é€’å½’æ¢ç´¢ç›®å½•ç»“æ„"""
            if level > max_level:  # é™åˆ¶æœ€å¤§å±‚çº§é˜²æ­¢è¿‡æ·±
                return
            
            try:
                items = list(dir_path.iterdir())
                
                # åˆ†ç¦»æ–‡ä»¶å’Œç›®å½•
                files = [item for item in items if item.is_file()]
                dirs = [item for item in items if item.is_dir()]
                
                # æ˜¾ç¤ºæ–‡ä»¶ï¼ˆé™åˆ¶æ•°é‡ï¼‰ï¼ŒåŒ…å«å®Œæ•´è·¯å¾„
                for i, file_item in enumerate(files[:max_files_per_dir]):
                    file_size = file_item.stat().st_size
                    relative_path = _get_relative_path(file_item)
                    structure_lines.append(f"{'  ' * level}ğŸ“„ {relative_path} ({self._format_file_size(file_size)})")
                    
                    # å¦‚æœæ˜¯ç‰¹æ®Šæ–‡ä»¶æ ¼å¼ï¼Œæ˜¾ç¤ºæ–‡ä»¶å†…å®¹ç¤ºä¾‹
                    if file_item.suffix.lower() in ['.xyz', '.csv', '.xlsx', '.json', '.jsonl', '.txt', '.md', '.tsv']:
                        try:
                            with open(file_item, 'r', encoding='utf-8', errors='ignore') as f:
                                first_lines = f.readlines()[:3]
                            structure_lines.append(f"{'  ' * level}    [å†…å®¹ç¤ºä¾‹]:")
                            for line in first_lines:
                                structure_lines.append(f"{'  ' * level}    {line.strip()}")
                            structure_lines.append(f"{'  ' * level}    ...")
                        except:
                            pass
                
                if len(files) > max_files_per_dir:
                    remaining_files = len(files) - max_files_per_dir
                    structure_lines.append(f"{'  ' * level}    ... è¿˜æœ‰{remaining_files}ä¸ªæ–‡ä»¶")
                
                # æ˜¾ç¤ºç›®å½•ï¼ˆé™åˆ¶æ•°é‡ï¼‰ï¼ŒåŒ…å«å®Œæ•´è·¯å¾„
                for i, dir_item in enumerate(dirs[:max_files_per_dir]):
                    relative_path = _get_relative_path(dir_item)
                    structure_lines.append(f"{'  ' * level}ğŸ“ {relative_path}/")
                    
                    # æ·±å…¥æ¢ç´¢ç›®å½•
                    if i < 5:  # æ¢ç´¢å‰5ä¸ªç›®å½•
                        _explore_directory(dir_item, level + 1, max_level)
                    elif i == 5 and len(dirs) > 5:
                        # å¯¹äºç¬¬6ä¸ªç›®å½•ï¼Œæ˜¾ç¤ºå…¶å†…å®¹ä½œä¸ºç¤ºä¾‹
                        try:
                            sub_items = list(dir_item.iterdir())
                            structure_lines.append(f"{'  ' * (level+1)}[ç¤ºä¾‹ç›®å½•å†…å®¹]:")
                            for j, sample_item in enumerate(sub_items[:3]):
                                if sample_item.is_file():
                                    file_size = sample_item.stat().st_size
                                    sample_relative_path = _get_relative_path(sample_item)
                                    structure_lines.append(f"{'  ' * (level+1)}ğŸ“„ {sample_relative_path} ({self._format_file_size(file_size)})")
                                    
                                    # æ˜¾ç¤ºæ–‡ä»¶å†…å®¹ç¤ºä¾‹
                                    if sample_item.suffix.lower() in ['.xyz', '.csv', '.xlsx', '.json', '.jsonl', '.txt', '.tsv']:
                                        try:
                                            with open(sample_item, 'r', encoding='utf-8', errors='ignore') as f:
                                                first_lines = f.readlines()[:3]
                                            structure_lines.append(f"{'  ' * (level+1)}    [å†…å®¹ç¤ºä¾‹]:")
                                            for line in first_lines:
                                                structure_lines.append(f"{'  ' * (level+1)}    {line.strip()}")
                                        except:
                                            pass
                                else:
                                    sample_relative_path = _get_relative_path(sample_item)
                                    structure_lines.append(f"{'  ' * (level+1)}ğŸ“ {sample_relative_path}/")
                            if len(sub_items) > 3:
                                structure_lines.append(f"{'  ' * (level+1)}    ... ç­‰å…±{len(sub_items)}ä¸ªé¡¹ç›®")
                        except:
                            pass
                
                if len(dirs) > max_files_per_dir:
                    remaining_dirs = len(dirs) - max_files_per_dir
                    structure_lines.append(f"{'  ' * level}    ... è¿˜æœ‰{remaining_dirs}ä¸ªç›®å½•")
                    
            except Exception as e:
                structure_lines.append(f"{'  ' * level}(æ— æ³•è¯»å–ç›®å½•å†…å®¹: {str(e)})")
        
        try:
            _explore_directory(path)
        except Exception as e:
            structure_lines.append(f"è¯»å–ç›®å½•å¤±è´¥: {str(e)}")
        
        return "\n".join(structure_lines)
    
    def _format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
        if size_bytes < 1024:
            return f"{size_bytes}B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes/1024:.1f}KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes/(1024*1024):.1f}MB"
        else:
            return f"{size_bytes/(1024*1024*1024):.1f}GB"
    
    def _build_structure_analysis_prompt(self, structure_summary: str) -> str:
        """æ„å»ºæ–‡ä»¶ç»“æ„åˆ†æçš„prompt"""
        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹æ•°æ®é›†çš„æ–‡ä»¶ç»“æ„ï¼Œåˆ¤æ–­æ•°æ®é›†çš„ç»„ç»‡æ–¹å¼å’Œæ–‡ä»¶åŠ è½½éœ€æ±‚ï¼š

        æ–‡ä»¶ç»“æ„ï¼š
        {structure_summary}

        è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼åˆ†æå¹¶è¿”å›ç»“æœï¼š
        
        è®­ç»ƒé›†æ–‡ä»¶: [è¯†åˆ«å“ªäº›æ˜¯è®­ç»ƒæ•°æ®æ–‡ä»¶]
        æµ‹è¯•é›†æ–‡ä»¶: [è¯†åˆ«å“ªäº›æ˜¯æµ‹è¯•æ•°æ®æ–‡ä»¶]
        éªŒè¯é›†æ–‡ä»¶: [è¯†åˆ«å“ªäº›æ˜¯éªŒè¯æ•°æ®æ–‡ä»¶ï¼Œå¦‚æœæœ‰çš„è¯]
        é¢å¤–æ–‡ä»¶: [è¯†åˆ«æ˜¯å¦æœ‰éœ€è¦é¢å¤–åŠ è½½çš„æ–‡ä»¶ï¼Œå¦‚å›¾ç‰‡ã€æ–‡æœ¬ç­‰]
        æ•°æ®æ ¼å¼: [åˆ¤æ–­æ•°æ®æ ¼å¼ï¼Œå¦‚CSVã€å›¾ç‰‡ã€æ–‡æœ¬ç­‰]
        åŠ è½½å»ºè®®: [ç»™å‡ºæ•°æ®åŠ è½½çš„å»ºè®®]

        è¦æ±‚ï¼š
        1. åŸºäºæ–‡ä»¶åå’Œç»“æ„åˆ¤æ–­æ•°æ®é›†çš„ç»„ç»‡æ–¹å¼
        2. è¯†åˆ«æ˜¯å¦éœ€è¦åŠ è½½é¢å¤–çš„æ–‡ä»¶ï¼ˆå¦‚å›¾ç‰‡æ–‡ä»¶å¤¹ï¼‰
        3. ç»™å‡ºåˆç†çš„æ•°æ®åŠ è½½ç­–ç•¥å»ºè®®
        4. ç”¨ä¸­æ–‡å›ç­”ï¼Œç®€æ´æ˜äº†
        """
        return prompt
    
    def _parse_structure_analysis(self, response: str) -> Dict[str, str]:
        """è§£æLLMçš„æ–‡ä»¶ç»“æ„åˆ†æå“åº”"""
        analysis = {
            "train_files": "",
            "test_files": "",
            "validation_files": "",
            "additional_files": "",
            "data_format": "",
            "loading_suggestions": ""
        }
        
        lines = response.strip().split('\n')
        current_key = None
        current_content = []
        
        for line in lines:
            line = line.strip()
            
            # å¤„ç†markdownæ ¼å¼çš„æ ‡é¢˜
            if "è®­ç»ƒé›†æ–‡ä»¶" in line and (":" in line or "**" in line):
                if current_key and current_content:
                    analysis[current_key] = "\n".join(current_content).strip()
                current_key = "train_files"
                current_content = []
                # æå–å†’å·åçš„å†…å®¹
                if ":" in line:
                    content = line.split(":", 1)[-1].strip()
                    if content:
                        current_content.append(content)
                        
            elif "æµ‹è¯•é›†æ–‡ä»¶" in line and (":" in line or "**" in line):
                if current_key and current_content:
                    analysis[current_key] = "\n".join(current_content).strip()
                current_key = "test_files"
                current_content = []
                if ":" in line:
                    content = line.split(":", 1)[-1].strip()
                    if content:
                        current_content.append(content)
                        
            elif "éªŒè¯é›†æ–‡ä»¶" in line and (":" in line or "**" in line):
                if current_key and current_content:
                    analysis[current_key] = "\n".join(current_content).strip()
                current_key = "validation_files"
                current_content = []
                if ":" in line:
                    content = line.split(":", 1)[-1].strip()
                    if content:
                        current_content.append(content)
                        
            elif "é¢å¤–æ–‡ä»¶" in line and (":" in line or "**" in line):
                if current_key and current_content:
                    analysis[current_key] = "\n".join(current_content).strip()
                current_key = "additional_files"
                current_content = []
                if ":" in line:
                    content = line.split(":", 1)[-1].strip()
                    if content:
                        current_content.append(content)
                        
            elif "æ•°æ®æ ¼å¼" in line and (":" in line or "**" in line):
                if current_key and current_content:
                    analysis[current_key] = "\n".join(current_content).strip()
                current_key = "data_format"
                current_content = []
                if ":" in line:
                    content = line.split(":", 1)[-1].strip()
                    if content:
                        current_content.append(content)
                        
            elif "åŠ è½½å»ºè®®" in line and (":" in line or "**" in line):
                if current_key and current_content:
                    analysis[current_key] = "\n".join(current_content).strip()
                current_key = "loading_suggestions"
                current_content = []
                if ":" in line:
                    content = line.split(":", 1)[-1].strip()
                    if content:
                        current_content.append(content)
                        
            elif current_key and line and not line.startswith("**") and line != "":
                # æ·»åŠ å†…å®¹è¡Œåˆ°å½“å‰å­—æ®µ
                current_content.append(line)
        
        # å¤„ç†æœ€åä¸€ä¸ªå­—æ®µ
        if current_key and current_content:
            analysis[current_key] = "\n".join(current_content).strip()
        
        return analysis
    
    def _extract_python_code(self, response: str) -> str:
        """ä»LLMå“åº”ä¸­æå–Pythonä»£ç """
        lines = response.split('\n')
        code_lines = []
        in_code_block = False
        
        for line in lines:
            if line.strip().startswith('```python') or line.strip().startswith('```Python'):
                in_code_block = True
                continue
            elif line.strip().startswith('```') and in_code_block:
                break
            elif in_code_block:
                code_lines.append(line)
        
        if not code_lines:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾å…¶ä»–æ ¼å¼
            for line in lines:
                if line.strip().startswith('```'):
                    in_code_block = not in_code_block
                    continue
                elif in_code_block:
                    code_lines.append(line)
        
        if not code_lines:
            # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œè¿”å›æ•´ä¸ªå“åº”çš„å¯èƒ½ä»£ç éƒ¨åˆ†
            self.logger.warning("æœªæ‰¾åˆ°æ ‡å‡†ä»£ç å—ï¼Œå°è¯•æå–æ•´ä¸ªå“åº”")
            return response.strip()
        
        return '\n'.join(code_lines)
    
    async def _debug_data_loader_with_retry(self, workspace_dir: Path, error_message: str) -> Dict[str, str]:
        """
        ä½¿ç”¨CodingAgentè°ƒè¯•ä¿®å¤æ•°æ®åŠ è½½ä»£ç 
        
        Args:
            workspace_dir: å·¥ä½œç›®å½•
            error_message: é”™è¯¯ä¿¡æ¯
            
        Returns:
            è°ƒè¯•ç»“æœ
        """
        try:
            loader_file = workspace_dir / "load_research_data.py"
            if not loader_file.exists():
                return {
                    "status": "error",
                    "message": "æ•°æ®åŠ è½½æ–‡ä»¶ä¸å­˜åœ¨"
                }
            
            self.logger.info("å¼€å§‹è°ƒè¯•æ•°æ®åŠ è½½ä»£ç ...")
            
            # è°ƒç”¨CodingAgentçš„debug_codeåŠŸèƒ½
            debug_result = await self.coding_agent.debug_code(
                code_path=str(loader_file),
                error_message=error_message,
                error_context="æ•°æ®åŠ è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œå¯èƒ½éœ€è¦å¤„ç†æ•°æ®ç±»å‹ã€ç¼ºå¤±å€¼æˆ–æ–‡ä»¶è·¯å¾„é—®é¢˜"
            )
            
            if debug_result['status'] == 'success':
                self.logger.info("æ•°æ®åŠ è½½ä»£ç è°ƒè¯•ä¿®å¤æˆåŠŸ")
                return {
                    "status": "success",
                    "message": "ä»£ç ä¿®å¤æˆåŠŸ"
                }
            else:
                self.logger.error(f"æ•°æ®åŠ è½½ä»£ç è°ƒè¯•å¤±è´¥: {debug_result.get('error', '')}")
                return {
                    "status": "error",
                    "message": f"ä»£ç è°ƒè¯•å¤±è´¥: {debug_result.get('error', '')}"
                }
                
        except Exception as e:
            self.logger.error(f"è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "message": f"è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {str(e)}"
            }
    
    def _get_submission_file_name(self, structure_info: Dict[str, str], benchmark_name: str = "mlebench") -> str:
        """
        ä»æ–‡ä»¶ç»“æ„ä¿¡æ¯ä¸­è·å–æäº¤æ–‡ä»¶å

        Args:
            structure_info: æ–‡ä»¶ç»“æ„ä¿¡æ¯
            benchmark_name: benchmarkåç§°

        Returns:
            æäº¤æ–‡ä»¶å
        """
        structure_summary = structure_info.get('structure_summary', '')
        analysis_result = structure_info.get('analysis_result', {})

        # ä»ç»“æ„æ‘˜è¦ä¸­æŸ¥æ‰¾submissionç›¸å…³æ–‡ä»¶
        if 'sample_submission' in structure_summary.lower() or 'submission' in structure_summary.lower():
            lines = structure_summary.split('\n')
            for line in lines:
                if 'submission' in line.lower():
                    # æ”¯æŒå¤šç§æ ¼å¼
                    for ext in ['.csv', '.xlsx', '.json', '.jsonl', '.txt']:
                        if ext in line.lower():
                            parts = line.split()
                            for part in parts:
                                if 'submission' in part.lower() and ext in part.lower():
                                    return part.split('/')[-1]  # åªè¦æ–‡ä»¶åéƒ¨åˆ†

        # ä»é¢å¤–æ–‡ä»¶ä¸­æŸ¥æ‰¾
        additional_files = analysis_result.get('additional_files', '')
        if 'submission' in additional_files.lower():
            # æ£€æŸ¥å¤šç§æ ¼å¼
            for ext in ['.csv', '.xlsx', '.json', '.jsonl', '.txt']:
                if f'submission{ext}' in additional_files.lower():
                    # æå–å®Œæ•´æ–‡ä»¶å
                    import re
                    pattern = rf'\S*submission\S*{ext}'
                    match = re.search(pattern, additional_files.lower())
                    if match:
                        return match.group(0)

        # æ ¹æ®benchmarkç±»å‹è¿”å›é»˜è®¤æäº¤æ–‡ä»¶å
        benchmark_submission_files = {
            "mlebench": "sample_submission.csv",
            "kaggle": "submission.csv",
            "default": "submission.csv"
        }

        return benchmark_submission_files.get(benchmark_name.lower(), benchmark_submission_files["default"])
    
    async def _generate_research_code(
        self,
        research_topic: str,
        research_goal: str,
        init_analysis: str,
        data_structure_info: str,
        submission_file_name: str,
        workspace_dir: Path
    ) -> Dict[str, str]:
        """
        ç”Ÿæˆç ”ç©¶ä»£ç 
        
        Args:
            research_topic: ç ”ç©¶ä¸»é¢˜
            research_goal: ç ”ç©¶ç›®æ ‡
            init_analysis: åˆæ­¥åˆ†æç»“æœ
            data_structure_info: æ•°æ®ç»“æ„ä¿¡æ¯
            submission_file_name: æäº¤æ–‡ä»¶å
            workspace_dir: å·¥ä½œç›®å½•
            
        Returns:
            ç”Ÿæˆç»“æœ
        """
        try:
            result = await self.coding_agent.generate_research_code(
                research_topic=research_topic,
                research_goal=research_goal,
                init_analysis=init_analysis,
                data_structure_info=data_structure_info,
                submission_file_name=submission_file_name,
                workspace_dir=str(workspace_dir),
                device_info=self.device_info
            )
            return result
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆç ”ç©¶ä»£ç æ—¶å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"ç”Ÿæˆç ”ç©¶ä»£ç å¤±è´¥: {str(e)}"
            }
    
    def _find_and_validate_output_files(self, workspace_dir: Path, benchmark_name: str = "mlebench") -> tuple:
        """
        æŸ¥æ‰¾å¹¶éªŒè¯è¾“å‡ºæ–‡ä»¶

        Args:
            workspace_dir: å·¥ä½œç›®å½•
            benchmark_name: benchmarkåç§°

        Returns:
            (valid_files, all_files): æœ‰æ•ˆæ–‡ä»¶åˆ—è¡¨å’Œæ‰€æœ‰æ‰¾åˆ°çš„æ–‡ä»¶åˆ—è¡¨
        """
        import pandas as pd

        # æ ¹æ®benchmarkç±»å‹å†³å®šæ£€æŸ¥å“ªäº›æ ¼å¼
        benchmark_file_patterns = {
            "mlebench": ["*.csv"],  # mlebenchä¸»è¦ä½¿ç”¨CSVæ ¼å¼
            "kaggle": ["*.csv"],
            "default": ["*.csv", "*.xlsx", "*.json", "*.jsonl", "*.txt"]  # å…¶ä»–benchmarkæ”¯æŒæ›´å¤šæ ¼å¼
        }

        file_patterns = benchmark_file_patterns.get(benchmark_name.lower(), benchmark_file_patterns["default"])

        all_files = []
        for pattern in file_patterns:
            all_files.extend(workspace_dir.glob(pattern))

        valid_files = []
        for file_path in all_files:
            try:
                # æ ¹æ®æ–‡ä»¶ç±»å‹éªŒè¯
                if file_path.suffix.lower() == '.csv':
                    df = pd.read_csv(file_path)
                    if len(df) > 0 and len(df.columns) >= 1:
                        valid_files.append(file_path)
                        self.logger.info(f"æœ‰æ•ˆæ–‡ä»¶: {file_path.name}, å½¢çŠ¶: {df.shape}")
                    else:
                        self.logger.warning(f"æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ•ˆ: {file_path.name}")
                elif file_path.suffix.lower() in ['.json', '.jsonl']:
                    # JSONæ–‡ä»¶åŸºæœ¬æ£€æŸ¥
                    if file_path.stat().st_size > 0:
                        valid_files.append(file_path)
                        self.logger.info(f"æœ‰æ•ˆæ–‡ä»¶: {file_path.name}, å¤§å°: {file_path.stat().st_size}")
                elif file_path.suffix.lower() in ['.txt', '.xlsx']:
                    # å…¶ä»–æ ¼å¼åªæ£€æŸ¥æ˜¯å¦éç©º
                    if file_path.stat().st_size > 0:
                        valid_files.append(file_path)
                        self.logger.info(f"æœ‰æ•ˆæ–‡ä»¶: {file_path.name}, å¤§å°: {file_path.stat().st_size}")
            except Exception as e:
                self.logger.warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path.name}: {e}")

        return valid_files, all_files

    async def _test_research_code(self, workspace_dir: Path, benchmark_name: str = "mlebench") -> Dict[str, str]:
        """
        æµ‹è¯•ç ”ç©¶ä»£ç 

        Args:
            workspace_dir: å·¥ä½œç›®å½•
            benchmark_name: benchmarkåç§°

        Returns:
            æµ‹è¯•ç»“æœ
        """
        try:
            research_file = workspace_dir / "research.py"
            if not research_file.exists():
                return {
                    "status": "error",
                    "error": "ç ”ç©¶ä»£ç æ–‡ä»¶ä¸å­˜åœ¨",
                    "message": "research.pyæ–‡ä»¶æœªæ‰¾åˆ°",
                    "detailed_error": "research.pyæ–‡ä»¶æœªæ‰¾åˆ°"
                }
            
            self.logger.info("æ‰§è¡Œç ”ç©¶ä»£ç æµ‹è¯•ï¼ˆå°æ ·æœ¬å¿«é€ŸéªŒè¯æ¨¡å¼ï¼‰...")
            
            # æ‰§è¡ŒPythonè„šæœ¬
            result = subprocess.run(
                ["python", "-u", "research.py"],
                cwd=str(workspace_dir),
                capture_output=True,
                text=True,
                timeout=600,  # 10åˆ†é’Ÿè¶…æ—¶
                env={**os.environ, "PYTHONUNBUFFERED": "1", "USE_SMALL_SAMPLE": "1", "QUICK_TEST": "1"}
            )
            
            # åˆå¹¶è¾“å‡º
            full_output = ""
            if result.stdout:
                full_output += result.stdout
            if result.stderr:
                full_output += "\n=== STDERR ===\n" + result.stderr
            
            if result.returncode == 0:
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸç”Ÿæˆäº†æœ‰æ•ˆçš„.csvæ–‡ä»¶
                submission_files = list(workspace_dir.glob("*.csv"))
                
                if submission_files:
                    # éªŒè¯submissionæ–‡ä»¶çš„æœ‰æ•ˆæ€§
                    valid_files = []
                    for csv_file in submission_files:
                        try:
                            import pandas as pd
                            df = pd.read_csv(csv_file)
                            # æ£€æŸ¥æ–‡ä»¶ä¸æ˜¯ç©ºçš„ï¼Œä¸”æœ‰å®é™…æ•°æ®è¡Œ
                            if len(df) > 0 and not df.empty:
                                # æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰1åˆ—æ•°æ®
                                if len(df.columns) >= 1:
                                    valid_files.append(csv_file)
                                    self.logger.info(f"æœ‰æ•ˆsubmissionæ–‡ä»¶: {csv_file.name}, å½¢çŠ¶: {df.shape}")
                                else:
                                    self.logger.warning(f"submissionæ–‡ä»¶åˆ—æ•°ä¸è¶³: {csv_file.name}, åˆ—æ•°: {len(df.columns)}")
                            else:
                                self.logger.warning(f"submissionæ–‡ä»¶ä¸ºç©º: {csv_file.name}")
                        except Exception as e:
                            self.logger.warning(f"æ— æ³•è¯»å–submissionæ–‡ä»¶ {csv_file.name}: {e}")
                    
                    if valid_files:
                        self.logger.info(f"ç ”ç©¶ä»£ç æ‰§è¡ŒæˆåŠŸï¼Œç”Ÿæˆäº†æœ‰æ•ˆsubmissionæ–‡ä»¶: {[str(f.name) for f in valid_files]}")
                        return {
                            "status": "success",
                            "stdout": result.stdout,
                            "stderr": result.stderr,
                            "output_info": full_output,
                            "submission_files": [str(f) for f in valid_files],
                            "message": "ç ”ç©¶ä»£ç æ‰§è¡Œå®Œæˆå¹¶ç”Ÿæˆäº†æœ‰æ•ˆsubmissionæ–‡ä»¶"
                        }
                    else:
                        self.logger.warning("ç”Ÿæˆçš„.csvæ–‡ä»¶æ— æ•ˆï¼ˆç©ºæ–‡ä»¶æˆ–æ ¼å¼é”™è¯¯ï¼‰")
                        error_details = f"Exit code: {result.returncode}\nSTDOUT:\n{result.stdout}\nSTDERR:\n{result.stderr}"
                        return {
                            "status": "error",
                            "stdout": result.stdout,
                            "stderr": result.stderr,
                            "returncode": result.returncode,
                            "output_info": full_output,
                            "detailed_error": f"ç”Ÿæˆçš„.csvæ–‡ä»¶æ— æ•ˆï¼ˆç©ºæ–‡ä»¶æˆ–æ ¼å¼é”™è¯¯ï¼‰ã€‚å®Œæ•´è¾“å‡º:\n{error_details}",
                            "message": "ç ”ç©¶ä»£ç æ‰§è¡Œå¤±è´¥ï¼šç”Ÿæˆçš„submissionæ–‡ä»¶æ— æ•ˆ"
                        }
                else:
                    self.logger.warning("ç ”ç©¶ä»£ç æ‰§è¡Œå®Œæˆä½†æœªç”Ÿæˆ.csvæ–‡ä»¶")
                    # å°†å®Œæ•´è¾“å‡ºä½œä¸ºé”™è¯¯ä¿¡æ¯ï¼Œæ–¹ä¾¿debug
                    error_details = f"Exit code: {result.returncode}\nSTDOUT:\n{result.stdout}\nSTDERR:\n{result.stderr}"
                    return {
                        "status": "error",
                        "stdout": result.stdout,
                        "stderr": result.stderr,
                        "returncode": result.returncode,
                        "output_info": full_output,
                        "detailed_error": f"ä»£ç æ‰§è¡Œå®Œæˆä½†æœªç”Ÿæˆ.csvæ–‡ä»¶ã€‚å®Œæ•´è¾“å‡º:\n{error_details}",
                        "message": "ç ”ç©¶ä»£ç æ‰§è¡Œå¤±è´¥ï¼šæœªç”Ÿæˆ.csvæ–‡ä»¶"
                    }
            else:
                self.logger.error(f"ç ”ç©¶ä»£ç æ‰§è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
                # è¿”å›å®Œæ•´çš„é”™è¯¯ä¿¡æ¯ï¼ŒåŒ…æ‹¬stdoutå’Œstderr
                error_details = f"Exit code: {result.returncode}\nSTDOUT:\n{result.stdout}\nSTDERR:\n{result.stderr}"
                return {
                    "status": "error",
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode,
                    "output_info": full_output,
                    "detailed_error": error_details,
                    "message": "ç ”ç©¶ä»£ç æ‰§è¡Œå¤±è´¥"
                }
                
        except subprocess.TimeoutExpired:
            self.logger.error("ç ”ç©¶ä»£ç æ‰§è¡Œè¶…æ—¶")
            return {
                "status": "error",
                "error": "æ‰§è¡Œè¶…æ—¶",
                "message": "ç ”ç©¶ä»£ç æ‰§è¡Œè¶…æ—¶",
                "detailed_error": "æ‰§è¡Œè¶…æ—¶"
            }
        except Exception as e:
            self.logger.error(f"ç ”ç©¶ä»£ç æµ‹è¯•å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"ç ”ç©¶ä»£ç æµ‹è¯•å¤±è´¥: {str(e)}",
                "detailed_error": str(e)
            }

    async def _run_full_research_code(self, workspace_dir: Path) -> Dict[str, str]:
        """
        è¿è¡Œå®Œæ•´æ•°æ®é›†çš„ç ”ç©¶ä»£ç 

        Args:
            workspace_dir: å·¥ä½œç›®å½•

        Returns:
            è¿è¡Œç»“æœ
        """
        try:
            research_file = workspace_dir / "research.py"
            if not research_file.exists():
                return {
                    "status": "error",
                    "error": "ç ”ç©¶ä»£ç æ–‡ä»¶ä¸å­˜åœ¨",
                    "message": "research.pyæ–‡ä»¶æœªæ‰¾åˆ°"
                }

            self.logger.info("æ‰§è¡Œå®Œæ•´æ•°æ®é›†è®­ç»ƒï¼ˆç§»é™¤ç¯å¢ƒå˜é‡é™åˆ¶ï¼‰...")

            # æ‰§è¡ŒPythonè„šæœ¬ï¼Œä¸è®¾ç½®USE_SMALL_SAMPLEå’ŒQUICK_TEST
            env = os.environ.copy()
            env.pop("USE_SMALL_SAMPLE", None)
            env.pop("QUICK_TEST", None)
            env["PYTHONUNBUFFERED"] = "1"

            result = subprocess.run(
                ["python", "-u", "research.py"],
                cwd=str(workspace_dir),
                capture_output=True,
                text=True,
                timeout=7200,  # 2å°æ—¶è¶…æ—¶ï¼ˆå®Œæ•´æ•°æ®é›†å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
                env=env
            )

            # åˆå¹¶è¾“å‡º
            full_output = ""
            if result.stdout:
                full_output += result.stdout
            if result.stderr:
                full_output += "\n=== STDERR ===\n" + result.stderr

            if result.returncode == 0:
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸç”Ÿæˆäº†æœ‰æ•ˆçš„.csvæ–‡ä»¶
                submission_files = list(workspace_dir.glob("*.csv"))

                if submission_files:
                    # éªŒè¯submissionæ–‡ä»¶çš„æœ‰æ•ˆæ€§
                    valid_files = []
                    for csv_file in submission_files:
                        try:
                            import pandas as pd
                            df = pd.read_csv(csv_file)
                            # æ£€æŸ¥æ–‡ä»¶ä¸æ˜¯ç©ºçš„ï¼Œä¸”æœ‰å®é™…æ•°æ®è¡Œ
                            if len(df) > 0 and not df.empty:
                                # æ£€æŸ¥æ˜¯å¦æœ‰åˆç†çš„åˆ—
                                if len(df.columns) >= 1:
                                    valid_files.append(csv_file)
                                    self.logger.info(f"å®Œæ•´è¿è¡Œç”Ÿæˆæœ‰æ•ˆsubmission: {csv_file.name}, å½¢çŠ¶: {df.shape}")
                                else:
                                    self.logger.warning(f"submissionæ–‡ä»¶åˆ—æ•°ä¸è¶³: {csv_file.name}")
                            else:
                                self.logger.warning(f"submissionæ–‡ä»¶ä¸ºç©º: {csv_file.name}")
                        except Exception as e:
                            self.logger.warning(f"æ— æ³•è¯»å–submissionæ–‡ä»¶ {csv_file.name}: {e}")

                    if valid_files:
                        self.logger.info(f"å®Œæ•´æ•°æ®é›†è®­ç»ƒæˆåŠŸï¼Œç”Ÿæˆsubmission: {[str(f.name) for f in valid_files]}")
                        return {
                            "status": "success",
                            "stdout": result.stdout,
                            "stderr": result.stderr,
                            "submission_files": [str(f.name) for f in valid_files],
                            "message": "å®Œæ•´æ•°æ®é›†è®­ç»ƒæˆåŠŸ"
                        }
                    else:
                        self.logger.warning("å®Œæ•´è¿è¡Œç”Ÿæˆçš„.csvæ–‡ä»¶æ— æ•ˆ")
                        return {
                            "status": "error",
                            "stdout": result.stdout,
                            "stderr": result.stderr,
                            "returncode": result.returncode,
                            "message": "å®Œæ•´è¿è¡Œç”Ÿæˆçš„submissionæ–‡ä»¶æ— æ•ˆ"
                        }
                else:
                    self.logger.warning("å®Œæ•´è¿è¡Œæœªç”Ÿæˆ.csvæ–‡ä»¶")
                    return {
                        "status": "error",
                        "stdout": result.stdout,
                        "stderr": result.stderr,
                        "returncode": result.returncode,
                        "message": "å®Œæ•´è¿è¡Œæœªç”Ÿæˆ.csvæ–‡ä»¶"
                    }
            else:
                self.logger.error(f"å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
                return {
                    "status": "error",
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode,
                    "message": f"å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}"
                }

        except subprocess.TimeoutExpired:
            self.logger.error("å®Œæ•´æ•°æ®é›†è¿è¡Œè¶…æ—¶ï¼ˆ2å°æ—¶ï¼‰")
            return {
                "status": "error",
                "error": "æ‰§è¡Œè¶…æ—¶",
                "message": "å®Œæ•´æ•°æ®é›†è¿è¡Œè¶…æ—¶"
            }
        except Exception as e:
            self.logger.error(f"å®Œæ•´æ•°æ®é›†è¿è¡Œå‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥: {str(e)}"
            }

    async def _debug_research_code_with_retry(self, workspace_dir: Path, error_message: str) -> Dict[str, str]:
        """
        ä½¿ç”¨CodingAgentè°ƒè¯•ä¿®å¤ç ”ç©¶ä»£ç 
        
        Args:
            workspace_dir: å·¥ä½œç›®å½•
            error_message: é”™è¯¯ä¿¡æ¯
            
        Returns:
            è°ƒè¯•ç»“æœ
        """
        try:
            research_file = workspace_dir / "research.py"
            if not research_file.exists():
                return {
                    "status": "error",
                    "message": "ç ”ç©¶ä»£ç æ–‡ä»¶ä¸å­˜åœ¨"
                }
            
            self.logger.info("å¼€å§‹è°ƒè¯•ç ”ç©¶ä»£ç ...")
            
            # è°ƒç”¨CodingAgentçš„debug_codeåŠŸèƒ½
            debug_result = await self.coding_agent.debug_code(
                code_path=str(research_file),
                error_message=error_message,
                error_context="ç ”ç©¶ä»£ç æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œå¯èƒ½éœ€è¦å¤„ç†æ¨¡å‹è®­ç»ƒã€æ•°æ®å¤„ç†æˆ–æ–‡ä»¶è¾“å‡ºé—®é¢˜"
            )
            
            if debug_result['status'] == 'success':
                self.logger.info("ç ”ç©¶ä»£ç è°ƒè¯•ä¿®å¤æˆåŠŸ")
                return {
                    "status": "success",
                    "message": "ä»£ç ä¿®å¤æˆåŠŸ"
                }
            else:
                self.logger.error(f"ç ”ç©¶ä»£ç è°ƒè¯•å¤±è´¥: {debug_result.get('error', '')}")
                return {
                    "status": "error",
                    "message": f"ä»£ç è°ƒè¯•å¤±è´¥: {debug_result.get('error', '')}"
                }
                
        except Exception as e:
            self.logger.error(f"è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "message": f"è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {str(e)}"
            }

    async def _evaluate_submission(
        self,
        workspace_dir: Path,
        dataset_name: str,
        benchmark_name: str
    ) -> Dict:
        """
        è¯„ä¼°æäº¤ç»“æœ

        Args:
            workspace_dir: å·¥ä½œç›®å½•
            dataset_name: æ•°æ®é›†åç§°
            benchmark_name: benchmarkåç§°

        Returns:
            è¯„ä¼°ç»“æœ
        """
        try:
            self.logger.info(f"å¼€å§‹è¯„ä¼°æäº¤ç»“æœ: benchmark={benchmark_name}, dataset={dataset_name}")

            # è·å–å¯¹åº”çš„è¯„ä¼°å™¨
            evaluator = self.evaluators.get(benchmark_name.lower())

            if not evaluator:
                self.logger.warning(f"æœªæ‰¾åˆ°benchmark '{benchmark_name}' çš„è¯„ä¼°å™¨ï¼Œè·³è¿‡è¯„ä¼°")
                return {
                    "status": "skipped",
                    "message": f"æœªæ‰¾åˆ°benchmark '{benchmark_name}' çš„è¯„ä¼°å™¨",
                    "valid_submission": None
                }

            # è°ƒç”¨è¯„ä¼°å™¨
            result = await evaluator.evaluate(workspace_dir, dataset_name, benchmark_name)

            return result

        except Exception as e:
            self.logger.error(f"è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"è¯„ä¼°å¤±è´¥: {str(e)}",
                "valid_submission": False
            }

    async def init_analyzing(
        self,
        research_topic: str,
        research_goal: str,
        dataset_path: str,
        data_structure_info: str,
        structure_analysis: Dict[str, str]
    ) -> Dict[str, str]:
        """
        åˆæ­¥åˆ†æï¼šåŸºäºæ•°æ®ç»“æ„å’Œç ”ç©¶ä»»åŠ¡è¿›è¡Œåˆæ­¥åˆ†æ
        
        Args:
            research_topic: ç ”ç©¶ä¸»é¢˜
            research_goal: ç ”ç©¶ç›®æ ‡
            dataset_path: æ•°æ®é›†è·¯å¾„
            data_structure_info: æ•°æ®ç»“æ„ä¿¡æ¯ï¼ˆä»data loaderè¾“å‡ºè·å–ï¼‰
            structure_analysis: æ–‡ä»¶ç»“æ„åˆ†æç»“æœ
        
        Returns:
            åˆæ­¥åˆ†æç»“æœ
        """
        self.logger.info("å¼€å§‹è¿›è¡Œåˆæ­¥æ•°æ®å’Œä»»åŠ¡åˆ†æ...")
        
        try:
            # æ„å»ºåˆæ­¥åˆ†æprompt
            prompt = f"""
            ä½œä¸ºä¸€åç»éªŒä¸°å¯Œçš„æœºå™¨å­¦ä¹ ç ”ç©¶å‘˜ï¼Œä½ éœ€è¦åŸºäºæ•°æ®ç»“æ„å’Œä»»åŠ¡ä¿¡æ¯ï¼Œç»™å‡ºæŠ€æœ¯è·¯çº¿åˆ†æå’Œå®ç°æ–¹æ¡ˆå»ºè®®ã€‚

            **ç ”ç©¶ä¸»é¢˜**:
            {research_topic}

            **ç ”ç©¶ç›®æ ‡**:
            {research_goal}

            **æ•°æ®åŠ è½½æµ‹è¯•ç»“æœ**:
            {data_structure_info}

            **æ–‡ä»¶ç»“æ„åˆ†æ**:
            è®­ç»ƒé›†æ–‡ä»¶: {structure_analysis.get('train_files', '')}
            æµ‹è¯•é›†æ–‡ä»¶: {structure_analysis.get('test_files', '')}
            æ•°æ®æ ¼å¼: {structure_analysis.get('data_format', '')}

            **æ•°æ®é›†è§„æ¨¡è¯„ä¼°**:
            è¯·æ ¹æ®ä¸Šè¿°ä¿¡æ¯è¯„ä¼°æ•°æ®é›†è§„æ¨¡ï¼Œå¹¶æ®æ­¤é€‰æ‹©åˆé€‚çš„æŠ€æœ¯æ–¹æ¡ˆï¼š
            - **å°æ•°æ®é›†**ï¼ˆ<10ä¸‡è¡Œï¼‰ï¼šå¯ä»¥ä½¿ç”¨ä»»ä½•sklearnæ¨¡å‹ï¼Œå†…å­˜å ç”¨ä¸æ˜¯é—®é¢˜
            - **ä¸­ç­‰æ•°æ®é›†**ï¼ˆ10ä¸‡-100ä¸‡è¡Œï¼‰ï¼šéœ€è¦æ³¨æ„å†…å­˜ä½¿ç”¨ï¼Œå¯ä½¿ç”¨sklearnä½†è¦ä¼˜åŒ–å‚æ•°
            - **å¤§æ•°æ®é›†**ï¼ˆ>100ä¸‡è¡Œï¼‰ï¼š**å¼ºçƒˆå»ºè®®ä½¿ç”¨æŸ¥æ‰¾è¡¨(lookup table)æˆ–ç®€å•è§„åˆ™æ–¹æ³•**ï¼Œé¿å…è®­ç»ƒå¤§å‹sklearnæ¨¡å‹å¯¼è‡´å†…å­˜æº¢å‡º
            - æ³¨æ„ï¼šå¦‚æœè®­ç»ƒæ•°æ®æ–‡ä»¶å¤§å°>100MBï¼Œé€šå¸¸æ„å‘³ç€æ˜¯å¤§æ•°æ®é›†

            è¯·åŸºäºä¸Šè¿°ä¿¡æ¯ï¼Œæä¾›æŠ€æœ¯è·¯çº¿åˆ†æå’Œæ–¹æ¡ˆå»ºè®®ï¼ˆä¸è¦å†™å…·ä½“å®ç°ä»£ç ï¼‰ï¼š

            ## 1. ä»»åŠ¡ç±»å‹è¯†åˆ«
            - è¿™æ˜¯ä»€ä¹ˆç±»å‹çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Ÿï¼ˆåˆ†ç±»/å›å½’/åºåˆ—é¢„æµ‹/èšç±»ç­‰ï¼‰
            - ä»»åŠ¡çš„éš¾ç‚¹å’ŒæŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿ
            - è¯„ä¼°æŒ‡æ ‡åº”è¯¥æ˜¯ä»€ä¹ˆï¼Ÿ

            ## 2. å¯è¡ŒæŠ€æœ¯è·¯çº¿ï¼ˆåˆ—ä¸¾å¤šä¸ªæ–¹æ¡ˆï¼‰
            è¯·åˆ—ä¸¾2-3ä¸ªå¯è¡Œçš„æŠ€æœ¯è·¯çº¿ï¼Œä»ç®€å•åˆ°å¤æ‚ï¼š

            **è·¯çº¿Aï¼ˆæœ€ç®€å•å¿«é€Ÿï¼‰**ï¼š
            - æŠ€æœ¯æ ˆï¼šï¼ˆå¦‚sklearnã€ä¼ ç»ŸMLç®—æ³•ï¼‰
            - æ¨¡å‹é€‰æ‹©ï¼šï¼ˆå…·ä½“ç®—æ³•ï¼Œå¦‚RandomForestã€LogisticRegressionç­‰ï¼‰
            - ç‰¹å¾å·¥ç¨‹ï¼šï¼ˆéœ€è¦æå–ä»€ä¹ˆç‰¹å¾ï¼‰
            - ä¼˜åŠ¿ï¼šï¼ˆä¸ºä»€ä¹ˆç®€å•å¿«é€Ÿï¼‰
            - é¢„æœŸæ•ˆæœï¼šï¼ˆbaselineæ€§èƒ½é¢„æœŸï¼‰

            **è·¯çº¿Bï¼ˆä¸­ç­‰å¤æ‚åº¦ï¼‰**ï¼š
            - æŠ€æœ¯æ ˆï¼šï¼ˆå¦‚XGBoostã€LightGBMç­‰ï¼‰
            - æ¨¡å‹é€‰æ‹©ï¼š
            - ç‰¹å¾å·¥ç¨‹ï¼š
            - ä¼˜åŠ¿ï¼š
            - é¢„æœŸæ•ˆæœï¼š

            **è·¯çº¿Cï¼ˆæ›´å¤æ‚/sotaæ–¹å‘ï¼‰**ï¼š
            - æŠ€æœ¯æ ˆï¼šï¼ˆå¦‚æ·±åº¦å­¦ä¹ ã€transformersç­‰ï¼‰
            - æ¨¡å‹é€‰æ‹©ï¼š
            - è®¾è®¡è¦ç‚¹ï¼š
            - ä¼˜åŠ¿ï¼š
            - é¢„æœŸæ•ˆæœï¼š

            ## 3. MVPæé€Ÿæ–¹æ¡ˆæ¨èï¼ˆæœ€é‡è¦ï¼‰
            **æ ¹æ®æ•°æ®é›†è§„æ¨¡æ¨èç¬¬ä¸€ç‰ˆbaselineæ–¹æ¡ˆ**ï¼š

            **é¦–å…ˆè¯„ä¼°æ•°æ®è§„æ¨¡**ï¼š
            - æŸ¥çœ‹æ–‡ä»¶å¤§å°ï¼ˆè®­ç»ƒé›†>100MBé€šå¸¸æ˜¯å¤§æ•°æ®é›†ï¼‰
            - ä¼°ç®—æ€»è¡Œæ•°ï¼ˆä»æµ‹è¯•ç»“æœä¸­è·å–ï¼‰

            **å°æ•°æ®é›†æ¨è**ï¼ˆ<10ä¸‡è¡Œï¼‰ï¼š
            - æŠ€æœ¯æ ˆï¼šsklearn + pandas
            - æ¨¡å‹ï¼šRandomForest/XGBoostç­‰ä¼ ç»ŸMLæ¨¡å‹
            - å¯ä»¥æ­£å¸¸ä½¿ç”¨model.fit()è®­ç»ƒ

            **å¤§æ•°æ®é›†æ¨è**ï¼ˆ>100ä¸‡è¡Œæˆ–æ–‡ä»¶>100MBï¼‰ï¼š
            - **å¼ºçƒˆæ¨è**ï¼šå†…å­˜é«˜æ•ˆçš„æ–¹æ³•ï¼ˆé¿å…å°†å…¨éƒ¨æ•°æ®åŠ è½½åˆ°å†…å­˜è¿›è¡Œè®­ç»ƒï¼‰
            - **ä¸¥ç¦**ï¼šè®­ç»ƒéœ€è¦å¤§é‡å†…å­˜çš„sklearnæ¨¡å‹ï¼ˆRandomForest/XGBoostç­‰ï¼‰
            - **åŸå› **ï¼šå¤§æ•°æ®é›†è®­ç»ƒsklearnæ¨¡å‹ä¼šå¯¼è‡´å†…å­˜æº¢å‡ºï¼ˆOOM killed, exit code -9ï¼‰
            - **é€šç”¨ç­–ç•¥**ï¼šæ ¹æ®ä»»åŠ¡ç‰¹ç‚¹é€‰æ‹©åˆé€‚çš„è½»é‡çº§æ–¹æ³•ï¼ˆå¦‚è®°å¿†åŒ–ã€å¢é‡å­¦ä¹ ã€è§„åˆ™æå–ç­‰ï¼‰

            **æ¨èæ–¹æ¡ˆè¯¦ç»†è¯´æ˜**ï¼š
            - **æ¨èæŠ€æœ¯æ ˆ**ï¼šï¼ˆæ ¹æ®æ•°æ®è§„æ¨¡æ˜ç¡®æŒ‡å®šï¼‰
            - **æ¨èæ–¹æ³•**ï¼šï¼ˆå…·ä½“æ–¹æ³•ç±»å‹ï¼šå†…å­˜é«˜æ•ˆæ–¹æ³•/sklearnæ¨¡å‹/æ·±åº¦å­¦ä¹ ï¼‰
            - **æ ¸å¿ƒç†ç”±**ï¼šï¼ˆä¸ºä»€ä¹ˆè¿™ä¸ªæ–¹æ¡ˆæœ€å¿«æœ€å¯é ï¼Œæ˜¯å¦è€ƒè™‘äº†å†…å­˜é™åˆ¶ï¼‰
            - **å†…å­˜ä¼°ç®—**ï¼šï¼ˆè¯„ä¼°æ–¹æ¡ˆæ˜¯å¦ä¼šå¯¼è‡´å†…å­˜é—®é¢˜ï¼‰
            - **å…³é”®æ­¥éª¤**ï¼š
              1. æ•°æ®é¢„å¤„ç†ï¼šï¼ˆå¦‚ä½•å¤„ç†æ•°æ®ï¼‰
              2. ä¸»è¦æ–¹æ³•ï¼šï¼ˆä½¿ç”¨ä½•ç§æŠ€æœ¯å®ç°ï¼‰
              3. Fallbackç­–ç•¥ï¼šï¼ˆå¯¹äºè¾¹ç•Œæƒ…å†µå¦‚ä½•å¤„ç†ï¼‰
              4. é¢„æµ‹è¾“å‡ºï¼šï¼ˆè¾“å‡ºæ ¼å¼ï¼‰
            - **é¢„è®¡å¼€å‘æ—¶é—´**ï¼šï¼ˆ15åˆ†é’Ÿå†…å¯å®Œæˆï¼‰
            - **æˆåŠŸç‡è¯„ä¼°**ï¼šï¼ˆè°ƒè¯•æˆåŠŸçš„å¯èƒ½æ€§ï¼Œæ˜¯å¦ä¼šOOMï¼‰

            ## 4. æ•°æ®å¤„ç†æ³¨æ„äº‹é¡¹
            - æ•°æ®ä¸­å¯èƒ½å­˜åœ¨çš„é—®é¢˜ï¼ˆç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ç­‰ï¼‰
            - éœ€è¦æ³¨æ„çš„æ•°æ®æ ¼å¼é—®é¢˜
            - è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ä¸€è‡´æ€§æ£€æŸ¥

            è¯·ç»™å‡ºæ¸…æ™°çš„æŠ€æœ¯è·¯çº¿åˆ†æï¼Œé‡ç‚¹æ¨èæœ€å¿«æœ€å¯è¡Œçš„MVPæ–¹æ¡ˆã€‚
            """

            # è°ƒç”¨LLMè¿›è¡Œåˆæ­¥åˆ†æ
            messages = [{"role": "user", "content": prompt}]
            response = await self.client.chat(messages, max_tokens=3000)
            
            self.logger.info("=== åˆæ­¥åˆ†æç»“æœ ===")
            self.logger.info(response)
            
            return {
                "status": "success",
                "analysis_content": response,
                "message": "åˆæ­¥åˆ†æå®Œæˆ"
            }
            
        except Exception as e:
            self.logger.error(f"åˆæ­¥åˆ†æå¤±è´¥: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"åˆæ­¥åˆ†æå¤±è´¥: {str(e)}"
            }
    
    def _create_workspace(self, benchmark_name: str, dataset_name: str) -> Path:
        """åˆ›å»ºå·¥ä½œç›®å½•"""
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        exp_id = f"exp_id_{timestamp}"
        
        # åˆ›å»ºå·¥ä½œç›®å½•è·¯å¾„
        workspace_dir = self.workspace_root / benchmark_name / dataset_name / exp_id
        workspace_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"åˆ›å»ºå·¥ä½œç›®å½•: {workspace_dir}")
        return workspace_dir
    
    async def _generate_data_loader(
        self, 
        structure_info: Dict[str, str], 
        dataset_path: str, 
        workspace_dir: Path
    ) -> Dict[str, str]:
        """ç”Ÿæˆæ•°æ®åŠ è½½ä»£ç """
        try:
            # æ„å»ºæ•°æ®åŠ è½½ä»£ç ç”Ÿæˆéœ€æ±‚
            analysis_result = structure_info.get('analysis_result', {})
            structure_summary = structure_info.get('structure_summary', '')
            
            requirements = f"""
            **é‡è¦ï¼šåªèƒ½ç”Ÿæˆä¸€ä¸ªæ–‡ä»¶load_research_data.pyï¼Œä¸è¦ç”Ÿæˆä»»ä½•å…¶ä»–æ–‡ä»¶ï¼**
            
            åˆ›å»ºä¸€ä¸ªæ•°æ®åŠ è½½è„šæœ¬ load_research_data.pyï¼Œè¦æ±‚ï¼š

            æ•°æ®é›†è·¯å¾„: {dataset_path}
            
            **å°æ ·æœ¬æ”¯æŒ**: è„šæœ¬éœ€è¦æ”¯æŒç¯å¢ƒå˜é‡USE_SMALL_SAMPLE=1æ—¶åªåŠ è½½å°‘é‡æ•°æ®ç”¨äºå¿«é€Ÿæµ‹è¯•
            
            æ–‡ä»¶ç»“æ„åˆ†æï¼ˆå®Œæ•´è·¯å¾„ç¤ºä¾‹ï¼‰:
            {structure_summary}
            
            è®­ç»ƒé›†æ–‡ä»¶: {analysis_result.get('train_files', '')}
            æµ‹è¯•é›†æ–‡ä»¶: {analysis_result.get('test_files', '')}
            æ•°æ®æ ¼å¼: {analysis_result.get('data_format', '')}
            åŠ è½½å»ºè®®: {analysis_result.get('loading_suggestions', '')}

            **æ•°æ®ç»„åˆè¦æ±‚ï¼š**
            å¦‚æœæ•°æ®é›†ä¸­åŒæ—¶åŒ…å«ç»“æ„åŒ–æ•°æ®ï¼ˆCSV/JSON/JSONLç­‰ï¼‰å’Œéç»“æ„åŒ–æ•°æ®ï¼ˆå›¾ç‰‡ã€éŸ³é¢‘ã€æ–‡æœ¬æ–‡ä»¶ç­‰ï¼‰ï¼Œ
            éœ€è¦æ™ºèƒ½åœ°å°†å®ƒä»¬ç»„åˆèµ·æ¥ï¼š
            
            1. **è¯†åˆ«å”¯ä¸€æ ‡è¯†ç¬¦**ï¼šåˆ†æç»“æ„åŒ–æ•°æ®çš„å­—æ®µï¼Œæ‰¾å‡ºå¯èƒ½çš„å”¯ä¸€æ ‡è¯†ç¬¦æˆ–æ–‡ä»¶å¼•ç”¨å­—æ®µ
            2. **æ•°æ®åŒ¹é…**ï¼šæ ¹æ®æ ‡è¯†ç¬¦å°†ç»“æ„åŒ–æ•°æ®ä¸å¯¹åº”çš„æ–‡ä»¶æ•°æ®åŒ¹é…
            3. **ç»Ÿä¸€æ ¼å¼**ï¼šè¿”å›ç»Ÿä¸€çš„æ•°æ®æ ¼å¼ï¼ŒåŒ…å«æ‰€æœ‰ç›¸å…³ä¿¡æ¯

            ä¾‹å¦‚ï¼š
            - å¦‚æœè¡¨æ ¼æ•°æ®ä¸­æœ‰æ–‡ä»¶è·¯å¾„/åç§°å­—æ®µï¼ŒåŒ¹é…å¯¹åº”çš„å¤–éƒ¨æ–‡ä»¶
            - å¦‚æœå…ƒæ•°æ®ä¸­æœ‰æ ‡è¯†ç¬¦å­—æ®µï¼ŒåŒ¹é…å¯¹åº”çš„æ•°æ®æ–‡ä»¶
            - å¦‚æœæ•°æ®ä¸­æœ‰æ ·æœ¬ç¼–å·ï¼ŒåŒ¹é…å¯¹åº”çš„æ•°æ®æ–‡ä»¶

            **ä¸¥æ ¼è¦æ±‚ï¼š**
            1. åªç”Ÿæˆä¸€ä¸ªæ–‡ä»¶load_research_data.pyï¼Œç»å¯¹ä¸è¦ç”Ÿæˆå…¶ä»–ä»»ä½•æ–‡ä»¶ï¼
            2. å®Œæ•´çš„importè¯­å¥
            3. ä¸€ä¸ªload_research_data()å‡½æ•°ï¼Œè¿”å›(train_data, test_data)
            4. æ ¹æ®æ–‡ä»¶ç»“æ„åˆ†æï¼Œç¼–å†™é€‚å½“çš„æ–‡ä»¶è§£æå‡½æ•°
            5. **æ•°æ®ç»„åˆå‡½æ•°**ï¼šå¦‚æœæœ‰å¤šç§æ•°æ®ç±»å‹ï¼Œç¼–å†™å‡½æ•°å°†å®ƒä»¬æ™ºèƒ½ç»„åˆ
            6. **å”¯ä¸€æ ‡è¯†ç¬¦è¯†åˆ«**ï¼šåˆ†æå¹¶æ‰¾å‡ºæ•°æ®é—´çš„å…³è”å­—æ®µ
            7. é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
            8. åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ if __name__ == "__main__":æµ‹è¯•ä»£ç 
            9. æµ‹è¯•ä»£ç è¦æ‰“å°å‰5ä¸ªè®­ç»ƒæ ·æœ¬çš„åŸºæœ¬ä¿¡æ¯ï¼Œå±•ç¤ºç»„åˆåçš„æ•°æ®ç»“æ„
            
            **æ•°æ®ç»„åˆç¤ºä¾‹ï¼š**
            ```python
            # ç¤ºä¾‹ï¼šç»„åˆè¡¨æ ¼æ ‡æ³¨æ•°æ®å’Œå¤–éƒ¨æ–‡ä»¶
            def combine_data(metadata, external_file_dir):
                combined_data = []
                for item in metadata:
                    # æ ¹æ®å…ƒæ•°æ®ä¸­çš„è·¯å¾„ä¿¡æ¯æ‰¾åˆ°å¯¹åº”æ–‡ä»¶
                    file_path = os.path.join(external_file_dir, item['file_reference'])
                    if os.path.exists(file_path):
                        combined_data.append({{
                            'file_path': file_path,
                            'metadata': item,
                            # å…¶ä»–ç›¸å…³å­—æ®µæ ¹æ®å®é™…æ•°æ®ç»“æ„æ·»åŠ 
                        }})
                return combined_data
            ```
            
            æ³¨æ„ï¼š
            - ç»å¯¹åªç”Ÿæˆä¸€ä¸ªæ–‡ä»¶ï¼Œæ–‡ä»¶åå¿…é¡»æ˜¯load_research_data.py
            - ä¸è¦ç”ŸæˆREADMEã€é…ç½®æ–‡ä»¶æˆ–ä»»ä½•å…¶ä»–æ–‡ä»¶
            - ä»£ç è¦èƒ½ç›´æ¥è¿è¡Œ
            - ä½¿ç”¨pandasã€numpyç­‰é€‚å½“çš„åº“å¤„ç†æ•°æ®
            - æ ¹æ®å®é™…æ–‡ä»¶æ ¼å¼ç¼–å†™å¯¹åº”çš„è§£æä»£ç 
            - å¯¹äºç‰¹æ®Šæ–‡ä»¶æ ¼å¼ï¼Œæ ¹æ®æ–‡ä»¶ç»“æ„åˆ†æä¸­çš„å†…å®¹ç¤ºä¾‹æ¥ç†è§£æ ¼å¼
            - **é‡ç‚¹**ï¼šæ™ºèƒ½è¯†åˆ«å’Œç»„åˆä¸åŒç±»å‹çš„æ•°æ®

            **æ•°æ®å®Œæ•´æ€§è¦æ±‚ï¼ˆéå¸¸é‡è¦ï¼‰**ï¼š
            - åœ¨åŠ è½½æ•°æ®æ—¶ï¼Œ**ç»å¯¹ä¸èƒ½**ä½¿ç”¨dropna()æˆ–è¿‡æ»¤æ‰NaN/None/ç©ºå€¼çš„è¡Œ
            - å¿…é¡»ä¿ç•™æ•°æ®é›†ä¸­çš„æ‰€æœ‰è¡Œï¼ŒåŒ…æ‹¬å«æœ‰ç¼ºå¤±å€¼çš„è¡Œ
            - å¯¹äºç¼ºå¤±å€¼ï¼Œåº”è¯¥ä¿æŒåŸæ ·ï¼ˆä¿ç•™NaNï¼‰æˆ–ç”¨æ˜ç¡®çš„é»˜è®¤å€¼å¡«å……ï¼Œä½†ä¸èƒ½åˆ é™¤è¡Œ
            - ç¡®ä¿load_research_data()è¿”å›çš„æ•°æ®è¡Œæ•°ä¸åŸå§‹æ–‡ä»¶å®Œå…¨ä¸€è‡´
            - è¿™æ˜¯ä¸ºäº†ä¿è¯åç»­ç”Ÿæˆçš„é¢„æµ‹ç»“æœèƒ½å¤Ÿä¸æµ‹è¯•é›†å®Œå…¨å¯¹åº”
            
            è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
            ```python
            # load_research_data.pyçš„å®Œæ•´ä»£ç 
            ```
            
            **å†æ¬¡å¼ºè°ƒï¼šåªè¾“å‡ºå•ä¸ªPythonæ–‡ä»¶(load_research_data.py)ï¼ŒåŒ…å«å®Œæ•´çš„æ•°æ®åŠ è½½å’Œç»„åˆé€»è¾‘ï¼**
            """
            
            # ç›´æ¥è°ƒç”¨LLMç”Ÿæˆä»£ç ï¼Œä¸é€šè¿‡CodingAgentçš„é¡¹ç›®ç»“æ„
            messages = [{"role": "user", "content": requirements}]
            response = await self.client.chat(messages, max_tokens=4000)
            
            # æå–Pythonä»£ç 
            python_code = self._extract_python_code(response)
            
            # ç›´æ¥ä¿å­˜åˆ°workspace_dir
            target_file = workspace_dir / "load_research_data.py"
            with open(target_file, 'w', encoding='utf-8') as f:
                f.write(python_code)
            
            result = {
                "status": "success",
                "generated_files": [str(target_file)],
                "message": "æ•°æ®åŠ è½½ä»£ç ç”ŸæˆæˆåŠŸ"
            }
            
            self.logger.info("æ•°æ®åŠ è½½ä»£ç ç”ŸæˆæˆåŠŸ")
            return result
                
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ•°æ®åŠ è½½ä»£ç æ—¶å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"ç”Ÿæˆæ•°æ®åŠ è½½ä»£ç å¤±è´¥: {str(e)}"
            }
    
    async def _test_data_loader(self, workspace_dir: Path) -> Dict[str, str]:
        """æ‰§è¡Œæ•°æ®åŠ è½½æµ‹è¯•å¹¶è¿”å›æ•°æ®ç»“æ„ä¿¡æ¯ï¼ˆæ— è®ºdebugæ¨¡å¼å¦‚ä½•éƒ½ä¼šæ‰§è¡Œï¼‰"""
        try:
            loader_file = workspace_dir / "load_research_data.py"
            if not loader_file.exists():
                return {
                    "status": "error",
                    "error": "æ•°æ®åŠ è½½æ–‡ä»¶ä¸å­˜åœ¨",
                    "message": "load_research_data.pyæ–‡ä»¶æœªæ‰¾åˆ°",
                    "data_structure_info": "",
                    "detailed_error": ""
                }
            
            self.logger.info("æ‰§è¡Œæ•°æ®åŠ è½½æµ‹è¯•ï¼ˆå°æ ·æœ¬æ¨¡å¼ï¼‰...")
            
            # æ‰§è¡ŒPythonè„šæœ¬ï¼Œç¡®ä¿æ•è·æ‰€æœ‰è¾“å‡º
            result = subprocess.run(
                ["python", "-u", "load_research_data.py"],  # -uç¡®ä¿è¾“å‡ºä¸ç¼“å†²
                cwd=str(workspace_dir),
                capture_output=True,
                text=True,
                timeout=120,  # å¢åŠ è¶…æ—¶æ—¶é—´
                env={**os.environ, "PYTHONUNBUFFERED": "1", "USE_SMALL_SAMPLE": "1"}  # æ·»åŠ å°æ ·æœ¬ç¯å¢ƒå˜é‡
            )
            
            # åˆå¹¶stdoutå’Œstderrä½œä¸ºå®Œæ•´è¾“å‡º
            full_output = ""
            if result.stdout:
                full_output += result.stdout
            if result.stderr:
                full_output += "\n=== STDERR ===\n" + result.stderr
            
            if result.returncode == 0:
                self.logger.info("æ•°æ®åŠ è½½æµ‹è¯•æˆåŠŸ")
                return {
                    "status": "success",
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "data_structure_info": result.stdout,
                    "detailed_error": "",
                    "message": "æ•°æ®åŠ è½½æµ‹è¯•å®Œæˆ"
                }
            else:
                self.logger.error(f"æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
                self.logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
                return {
                    "status": "error",
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode,
                    "data_structure_info": full_output,  # åŒ…å«æ‰€æœ‰è¾“å‡ºä¿¡æ¯
                    "detailed_error": result.stderr,  # è¯¦ç»†é”™è¯¯ä¿¡æ¯
                    "message": "æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥"
                }
                
        except subprocess.TimeoutExpired:
            self.logger.error("æ•°æ®åŠ è½½æµ‹è¯•è¶…æ—¶")
            return {
                "status": "error",
                "error": "æ‰§è¡Œè¶…æ—¶",
                "message": "æ•°æ®åŠ è½½æµ‹è¯•è¶…æ—¶",
                "data_structure_info": "",
                "detailed_error": "æ‰§è¡Œè¶…æ—¶"
            }
        except Exception as e:
            self.logger.error(f"æ•°æ®åŠ è½½æµ‹è¯•å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {str(e)}",
                "data_structure_info": "",
                "detailed_error": str(e)
            }


# ä¾¿æ·å‡½æ•°
async def run_research_pipeline(
    research_topic: str,
    research_goal: str,
    dataset_path: str
) -> Dict[str, str]:
    """æ‰§è¡Œç ”ç©¶æµæ°´çº¿çš„ä¾¿æ·å‡½æ•°"""
    agent = InterAgent()
    return await agent.run_research_task(research_topic, research_goal, dataset_path)