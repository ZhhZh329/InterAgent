import os
import asyncio
import logging
import subprocess
from typing import Dict, List, Optional, TypedDict
from pathlib import Path
from datetime import datetime
from src.utils.openai_client import get_client
from src.InterAgent.coding_agent import CodingAgent
from src.mle_bench.evaluator_agent import MLEBenchEvaluator
from src.InterAgent.inter_agent_prompts import (
    build_structure_analysis_prompt,
    build_init_analysis_prompt,
    build_data_loader_generation_prompt
)


# LangGraph Stateå®šä¹‰
class ResearchState(TypedDict, total=False):
    """ç ”ç©¶ä»»åŠ¡çš„å®Œæ•´çŠ¶æ€"""
    # è¾“å…¥å‚æ•°
    research_topic: str
    research_goal: str
    dataset_path: str
    benchmark_name: str
    dataset_name: str
    debug: bool
    workspace_dir: Path

    # æ–‡ä»¶ç»“æ„ç›¸å…³
    structure_info: Dict

    # æ•°æ®åŠ è½½ç›¸å…³
    data_loader_result: Dict
    test_result: Dict

    # åˆ†æç›¸å…³
    init_analysis_result: Dict

    # ç ”ç©¶ä»£ç ç›¸å…³
    research_code_result: Dict
    research_test_result: Dict
    submission_file_name: str

    # å®Œæ•´è¿è¡Œç›¸å…³
    full_run_result: Dict

    # è¯„ä¼°ç›¸å…³
    evaluation_result: Dict

    # é‡è¯•è®¡æ•°å™¨
    install_attempts: int
    debug_retry_count: int
    full_run_retry_count: int
    evaluation_retry_count: int
    regeneration_count: int

    # æœ€ç»ˆç»“æœ
    status: str
    message: str
    error: Optional[str]


class InterAgent:
    """ä¸»è¦çš„ç ”ç©¶ä»£ç†ï¼Œè´Ÿè´£åè°ƒæ•´ä¸ªç ”ç©¶ä»»åŠ¡æµç¨‹"""

    def __init__(self, model_name: Optional[str] = None, device_info: Optional[Dict] = None):
        self.client = get_client(model_name)
        self.coding_agent = CodingAgent(model_name)
        self.logger = logging.getLogger(__name__)
        self.workspace_root = Path("workspaces")
        self.device_info = device_info or {'device_type': 'cpu', 'device_name': 'CPU'}

        # åˆå§‹åŒ–è¯„ä¼°å™¨å­—å…¸
        self.evaluators = {
            'mlebench': MLEBenchEvaluator()
        }

    # ===== LangGraph Node Functions =====
    # These are wrapper nodes that call existing methods

    async def node_setup(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹: åˆå§‹åŒ–å·¥ä½œç›®å½•"""
        workspace_dir = self._create_workspace(state['benchmark_name'], state['dataset_name'])
        self.logger.info(f"å·¥ä½œç›®å½•: {workspace_dir}")
        return {'workspace_dir': workspace_dir}

    async def node_probe_structure(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹: æ¢æµ‹æ–‡ä»¶ç»“æ„"""
        structure_info = await self.file_structure_probing(state['dataset_path'])
        self.logger.info(f"æ–‡ä»¶ç»“æ„åˆ†æå®Œæˆ: {structure_info['status']}")
        return {'structure_info': structure_info}

    async def node_generate_data_loader(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹: ç”Ÿæˆæ•°æ®åŠ è½½ä»£ç """
        data_loader_result = await self._generate_data_loader(
            state['structure_info'],
            state['dataset_path'],
            state['workspace_dir']
        )
        self.logger.info(f"æ•°æ®åŠ è½½ä»£ç ç”Ÿæˆ: {data_loader_result['status']}")
        return {'data_loader_result': data_loader_result}

    async def node_test_data_loader(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹: æµ‹è¯•æ•°æ®åŠ è½½"""
        test_result = await self._test_data_loader(state['workspace_dir'])
        self.logger.info(f"æ•°æ®åŠ è½½æµ‹è¯•: {test_result['status']}")
        return {'test_result': test_result}

    async def node_debug_data_loader(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹: Debugæ•°æ®åŠ è½½ä»£ç """
        debug_result = await self._debug_data_loader_with_retry(
            state['workspace_dir'],
            state['test_result'].get('detailed_error', '')
        )
        if debug_result['status'] == 'success':
            # é‡æ–°æµ‹è¯•
            test_result = await self._test_data_loader(state['workspace_dir'])
            self.logger.info(f"ä¿®å¤åæ•°æ®åŠ è½½æµ‹è¯•: {test_result['status']}")
            return {'test_result': test_result}
        return {}

    async def node_init_analysis(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹: åˆæ­¥åˆ†æ"""
        init_analysis_result = await self.init_analyzing(
            research_topic=state['research_topic'],
            research_goal=state['research_goal'],
            dataset_path=state['dataset_path'],
            data_structure_info=state['test_result'].get('data_structure_info', ''),
            structure_analysis=state['structure_info'].get('analysis_result', {})
        )
        self.logger.info(f"åˆæ­¥åˆ†æ: {init_analysis_result['status']}")
        return {'init_analysis_result': init_analysis_result}

    async def node_generate_research_code(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹: ç”Ÿæˆç ”ç©¶ä»£ç """
        submission_file_name = self._get_submission_file_name(
            state['structure_info'],
            state['benchmark_name']
        )

        research_code_result = await self._generate_research_code(
            research_topic=state['research_topic'],
            research_goal=state['research_goal'],
            init_analysis=state['init_analysis_result']['analysis_content'],
            data_structure_info=state['test_result']['data_structure_info'],
            submission_file_name=submission_file_name,
            workspace_dir=state['workspace_dir']
        )
        self.logger.info(f"ç ”ç©¶ä»£ç ç”Ÿæˆ: {research_code_result['status']}")

        return {
            'submission_file_name': submission_file_name,
            'research_code_result': research_code_result
        }

    async def node_test_research_code(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹: æµ‹è¯•ç ”ç©¶ä»£ç ï¼ˆå°æ ·æœ¬ï¼‰"""
        research_test_result = await self._test_research_code(state['workspace_dir'])
        self.logger.info(f"ç ”ç©¶ä»£ç æµ‹è¯•: {research_test_result['status']}")
        return {'research_test_result': research_test_result}

    async def node_auto_fix_code(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹: è‡ªåŠ¨ä¿®å¤ä»£ç é—®é¢˜ï¼ˆä¾èµ–å®‰è£…+debug+é‡æ–°ç”Ÿæˆï¼‰"""
        self.logger.info("ç ”ç©¶ä»£ç æ‰§è¡Œå¤±è´¥ï¼Œå¯åŠ¨è‡ªåŠ¨debugå¾ªç¯...")
        fix_result = await self._auto_fix_code_issues(
            workspace_dir=state['workspace_dir'],
            research_test_result=state['research_test_result'],
            research_topic=state['research_topic'],
            research_goal=state['research_goal'],
            init_analysis_result=state['init_analysis_result'],
            test_result=state['test_result'],
            submission_file_name=state['submission_file_name'],
            current_regeneration_count=state.get('regeneration_count', 0)
        )

        return {
            'research_test_result': fix_result['final_test_result'],
            'install_attempts': fix_result['install_attempts'],
            'debug_retry_count': fix_result['debug_retry_count'],
            'regeneration_count': fix_result['regeneration_count']
        }

    async def node_run_full_dataset(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹: è¿è¡Œå®Œæ•´æ•°æ®é›†"""
        self.logger.info("=" * 80)
        self.logger.info("å°æ ·æœ¬æµ‹è¯•é€šè¿‡ï¼Œå¼€å§‹è¿è¡Œå®Œæ•´æ•°æ®é›†...")
        self.logger.info("=" * 80)
        full_run_result = await self._run_full_research_code(state['workspace_dir'])
        self.logger.info(f"å®Œæ•´æ•°æ®é›†è¿è¡Œ: {full_run_result['status']}")
        return {'full_run_result': full_run_result}

    async def node_optimize_full_run(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹: ä¼˜åŒ–å¹¶é‡è¯•å®Œæ•´æ•°æ®é›†è¿è¡Œï¼ˆä¸debugå¤±è´¥å…±äº«regeneration_countï¼‰"""
        self.logger.error(f"å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥: {state['full_run_result'].get('message', '')}")
        optimize_result = await self._optimize_and_retry_full_run(
            workspace_dir=state['workspace_dir'],
            full_run_result=state['full_run_result'],
            research_topic=state['research_topic'],
            research_goal=state['research_goal'],
            init_analysis_result=state['init_analysis_result'],
            test_result=state['test_result'],
            submission_file_name=state['submission_file_name'],
            dataset_name=state['dataset_name'],
            benchmark_name=state['benchmark_name'],
            current_regeneration_count=state.get('regeneration_count', 0)
        )

        return {
            'full_run_result': optimize_result['final_full_run_result'],
            'regeneration_count': optimize_result['regeneration_count']
        }

    async def node_evaluate(self, state: ResearchState) -> ResearchState:
        """èŠ‚ç‚¹: è¯„ä¼°æäº¤ç»“æœ"""
        self.logger.info("å®Œæ•´æ•°æ®é›†è®­ç»ƒæˆåŠŸï¼")
        self.logger.info(f"ç”Ÿæˆçš„submissionæ–‡ä»¶: {state['full_run_result'].get('submission_files', [])}")

        evaluation_result = await self._evaluate_submission(
            state['workspace_dir'],
            state['dataset_name'],
            state['benchmark_name']
        )

        # æ›´æ–°full_run_resultä¸­çš„evaluation
        full_run_result = state['full_run_result'].copy()
        full_run_result['evaluation'] = evaluation_result

        # å®æ—¶è¾“å‡ºè¯„ä¼°ç»“æœï¼Œæ–¹ä¾¿ç”¨æˆ·æŸ¥çœ‹æ‰§è¡Œè¿›åº¦
        if evaluation_result['status'] == 'success':
            self.logger.info("=" * 80)
            self.logger.info("=== è¯„ä¼°ç»“æœ ===")
            self.logger.info(f"åˆ†æ•°: {evaluation_result.get('score', 'N/A')}")
            self.logger.info(f"é‡‘ç‰Œ: {'æ˜¯' if evaluation_result.get('gold_medal') else 'å¦'}")
            self.logger.info(f"é“¶ç‰Œ: {'æ˜¯' if evaluation_result.get('silver_medal') else 'å¦'}")
            self.logger.info(f"é“œç‰Œ: {'æ˜¯' if evaluation_result.get('bronze_medal') else 'å¦'}")
            self.logger.info(f"è¶…è¿‡ä¸­ä½æ•°: {'æ˜¯' if evaluation_result.get('above_median') else 'å¦'}")
            self.logger.info(f"æäº¤æœ‰æ•ˆ: {'æ˜¯' if evaluation_result.get('valid_submission') else 'å¦'}")
            self.logger.info(evaluation_result.get('message', ''))
            self.logger.info("=" * 80)
        else:
            self.logger.error("=" * 80)
            self.logger.error("=== è¯„ä¼°å¤±è´¥ ===")
            self.logger.error(f"é”™è¯¯: {evaluation_result.get('error_message', 'unknown')}")
            self.logger.error(f"å¤±è´¥ç±»å‹: {evaluation_result.get('failure_type', 'unknown')}")
            self.logger.error("=" * 80)

        return {
            'evaluation_result': evaluation_result,
            'full_run_result': full_run_result
        }

    # ===== Routing Functions =====
    # These determine which node to go to next

    def route_after_data_loader_test(self, state: ResearchState) -> str:
        """è·¯ç”±: æ•°æ®åŠ è½½æµ‹è¯•å"""
        if state['test_result']['status'] == 'error' and state['test_result'].get('detailed_error'):
            return "debug_data_loader"
        return "init_analysis"

    def route_after_data_loader_debug(self, state: ResearchState) -> str:
        """è·¯ç”±: æ•°æ®åŠ è½½debugå"""
        # æ— è®ºdebugæˆåŠŸæˆ–å¤±è´¥ï¼Œéƒ½è¿›å…¥init_analysisï¼ˆä½¿ç”¨ç°æœ‰çš„test_resultï¼‰
        return "init_analysis"

    def route_after_init_analysis(self, state: ResearchState) -> str:
        """è·¯ç”±: åˆæ­¥åˆ†æå"""
        if state.get('init_analysis_result') and state['init_analysis_result']['status'] == 'success':
            return "generate_research_code"
        return "end"

    def route_after_research_code_test(self, state: ResearchState) -> str:
        """è·¯ç”±: ç ”ç©¶ä»£ç æµ‹è¯•å"""
        if state['research_test_result']['status'] == 'error' and state['research_test_result'].get('detailed_error'):
            return "auto_fix_code"
        return "run_full_dataset"

    def route_after_auto_fix(self, state: ResearchState) -> str:
        """è·¯ç”±: è‡ªåŠ¨ä¿®å¤å"""
        if state['research_test_result']['status'] == 'success':
            return "run_full_dataset"
        return "end"

    def route_after_full_run(self, state: ResearchState) -> str:
        """è·¯ç”±: å®Œæ•´è¿è¡Œå"""
        if state['full_run_result']['status'] == 'success':
            return "evaluate"
        return "optimize_full_run"

    def route_after_optimize(self, state: ResearchState) -> str:
        """è·¯ç”±: ä¼˜åŒ–é‡è¯•å"""
        if state['full_run_result']['status'] == 'success':
            return "evaluate"
        return "end"

    def route_after_evaluate(self, state: ResearchState) -> str:
        """è·¯ç”±: è¯„ä¼°å"""
        # è¯„ä¼°å®Œæˆåç»“æŸï¼ˆevaluation retry logicæš‚æ—¶ç®€åŒ–ï¼Œå¾…æœªæ¥æ‰©å±•ï¼‰
        return "end"

    def build_research_graph(self):
        """æ„å»ºLangGraphç ”ç©¶æµç¨‹å›¾"""
        from langgraph.graph import StateGraph, END

        # åˆ›å»ºStateGraph
        graph = StateGraph(ResearchState)

        # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
        graph.add_node("setup", self.node_setup)
        graph.add_node("probe_structure", self.node_probe_structure)
        graph.add_node("generate_data_loader", self.node_generate_data_loader)
        graph.add_node("test_data_loader", self.node_test_data_loader)
        graph.add_node("debug_data_loader", self.node_debug_data_loader)
        graph.add_node("init_analysis", self.node_init_analysis)
        graph.add_node("generate_research_code", self.node_generate_research_code)
        graph.add_node("test_research_code", self.node_test_research_code)
        graph.add_node("auto_fix_code", self.node_auto_fix_code)
        graph.add_node("run_full_dataset", self.node_run_full_dataset)
        graph.add_node("optimize_full_run", self.node_optimize_full_run)
        graph.add_node("evaluate", self.node_evaluate)

        # è®¾ç½®å…¥å£ç‚¹
        graph.set_entry_point("setup")

        # æ·»åŠ è¾¹ï¼ˆå®šä¹‰æµç¨‹ï¼‰
        graph.add_edge("setup", "probe_structure")
        graph.add_edge("probe_structure", "generate_data_loader")
        graph.add_edge("generate_data_loader", "test_data_loader")

        # æ¡ä»¶è¾¹: æ•°æ®åŠ è½½æµ‹è¯•å
        graph.add_conditional_edges(
            "test_data_loader",
            self.route_after_data_loader_test,
            {
                "debug_data_loader": "debug_data_loader",
                "init_analysis": "init_analysis"
            }
        )

        # æ¡ä»¶è¾¹: æ•°æ®åŠ è½½debugå
        graph.add_conditional_edges(
            "debug_data_loader",
            self.route_after_data_loader_debug,
            {
                "init_analysis": "init_analysis"
            }
        )

        # æ¡ä»¶è¾¹: åˆæ­¥åˆ†æå
        graph.add_conditional_edges(
            "init_analysis",
            self.route_after_init_analysis,
            {
                "generate_research_code": "generate_research_code",
                "end": END
            }
        )

        # ç›´æ¥è¾¹
        graph.add_edge("generate_research_code", "test_research_code")

        # æ¡ä»¶è¾¹: ç ”ç©¶ä»£ç æµ‹è¯•å
        graph.add_conditional_edges(
            "test_research_code",
            self.route_after_research_code_test,
            {
                "auto_fix_code": "auto_fix_code",
                "run_full_dataset": "run_full_dataset"
            }
        )

        # æ¡ä»¶è¾¹: è‡ªåŠ¨ä¿®å¤å
        graph.add_conditional_edges(
            "auto_fix_code",
            self.route_after_auto_fix,
            {
                "run_full_dataset": "run_full_dataset",
                "end": END
            }
        )

        # æ¡ä»¶è¾¹: å®Œæ•´è¿è¡Œå
        graph.add_conditional_edges(
            "run_full_dataset",
            self.route_after_full_run,
            {
                "evaluate": "evaluate",
                "optimize_full_run": "optimize_full_run"
            }
        )

        # æ¡ä»¶è¾¹: ä¼˜åŒ–å
        graph.add_conditional_edges(
            "optimize_full_run",
            self.route_after_optimize,
            {
                "evaluate": "evaluate",
                "end": END
            }
        )

        # æ¡ä»¶è¾¹: è¯„ä¼°å
        graph.add_conditional_edges(
            "evaluate",
            self.route_after_evaluate,
            {
                "end": END
            }
        )

        # ç¼–è¯‘graph
        return graph.compile()

    async def file_structure_probing(self, dataset_path: str) -> Dict[str, str]:
        """
        æ–‡ä»¶ç»“æ„æ¢æµ‹ï¼Œåˆ†ææ•°æ®é›†ç»“æ„å¹¶åˆ¤æ–­æ–‡ä»¶åŠ è½½éœ€æ±‚
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„
        
        Returns:
            DictåŒ…å«ç»“æ„åˆ†æç»“æœ
        """
        self.logger.info(f"å¼€å§‹æ¢æµ‹æ–‡ä»¶ç»“æ„: {dataset_path}")
        
        try:
            # è·å–æ•°æ®é›†ç›®å½•ç»“æ„ä¿¡æ¯
            structure_summary = self._get_directory_structure(dataset_path)
            
            # æ„å»ºåˆ†æprompt
            prompt = self._build_structure_analysis_prompt(structure_summary)
            
            # è°ƒç”¨LLMåˆ†ææ–‡ä»¶ç»“æ„
            messages = [{"role": "user", "content": prompt}]
            response = await self.client.chat(messages, max_tokens=2000)
            
            # å®æ—¶è¾“å‡ºLLMå“åº”ï¼Œæ–¹ä¾¿æŸ¥çœ‹æ‰§è¡Œè¿›åº¦
            self.logger.info(f"LLMæ–‡ä»¶ç»“æ„åˆ†æå“åº”: {response}")
            
            # è§£æLLMå“åº”
            analysis_result = self._parse_structure_analysis(response)
            
            self.logger.info("æ–‡ä»¶ç»“æ„æ¢æµ‹å®Œæˆ")
            
            return {
                "status": "success",
                "dataset_path": dataset_path,
                "structure_summary": structure_summary,
                "analysis_result": analysis_result,
                "message": "æ–‡ä»¶ç»“æ„åˆ†æå®Œæˆ"
            }
            
        except Exception as e:
            self.logger.error(f"æ–‡ä»¶ç»“æ„æ¢æµ‹å¤±è´¥: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"æ–‡ä»¶ç»“æ„æ¢æµ‹å¤±è´¥: {str(e)}"
            }
    
    def _get_directory_structure(self, dataset_path: str, max_files_per_dir: int = 10) -> str:
        """
        è·å–ç›®å½•ç»“æ„æ‘˜è¦ï¼Œé€’å½’éå†æ‰€æœ‰ç›®å½•å±‚çº§ï¼Œæ˜¾ç¤ºå®Œæ•´è·¯å¾„å¸®åŠ©LLMç†è§£æ–‡ä»¶æ ¼å¼
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„
            max_files_per_dir: æ¯ä¸ªç›®å½•æœ€å¤§æ–‡ä»¶æ•°é™åˆ¶
        
        Returns:
            ç›®å½•ç»“æ„çš„å­—ç¬¦ä¸²æè¿°
        """
        path = Path(dataset_path)
        if not path.exists():
            return f"è·¯å¾„ä¸å­˜åœ¨: {dataset_path}"
        
        structure_lines = []
        structure_lines.append(f"æ•°æ®é›†æ ¹ç›®å½•: {dataset_path}")
        structure_lines.append("")
        structure_lines.append("æ–‡ä»¶ç»“æ„åˆ†æ:")
        
        def _get_relative_path(file_path: Path) -> str:
            """è·å–ç›¸å¯¹äºæ•°æ®é›†æ ¹ç›®å½•çš„è·¯å¾„"""
            try:
                return f"./{file_path.relative_to(path)}"
            except ValueError:
                return str(file_path)
        
        def _explore_directory(dir_path: Path, level: int = 0, max_level: int = 4):
            """é€’å½’æ¢ç´¢ç›®å½•ç»“æ„"""
            if level > max_level:  # é™åˆ¶æœ€å¤§å±‚çº§é˜²æ­¢è¿‡æ·±
                return
            
            try:
                items = list(dir_path.iterdir())
                
                # åˆ†ç¦»æ–‡ä»¶å’Œç›®å½•
                files = [item for item in items if item.is_file()]
                dirs = [item for item in items if item.is_dir()]
                
                # æ˜¾ç¤ºæ–‡ä»¶ï¼ˆé™åˆ¶æ•°é‡ï¼‰ï¼ŒåŒ…å«å®Œæ•´è·¯å¾„
                for i, file_item in enumerate(files[:max_files_per_dir]):
                    file_size = file_item.stat().st_size
                    relative_path = _get_relative_path(file_item)
                    structure_lines.append(f"{'  ' * level}ğŸ“„ {relative_path} ({self._format_file_size(file_size)})")
                    
                    # å¦‚æœæ˜¯ç‰¹æ®Šæ–‡ä»¶æ ¼å¼ï¼Œæ˜¾ç¤ºæ–‡ä»¶å†…å®¹ç¤ºä¾‹
                    if file_item.suffix.lower() in ['.xyz', '.csv', '.xlsx', '.json', '.jsonl', '.txt', '.md', '.tsv']:
                        try:
                            with open(file_item, 'r', encoding='utf-8', errors='ignore') as f:
                                first_lines = f.readlines()[:3]
                            structure_lines.append(f"{'  ' * level}    [å†…å®¹ç¤ºä¾‹]:")
                            for line in first_lines:
                                structure_lines.append(f"{'  ' * level}    {line.strip()}")
                            structure_lines.append(f"{'  ' * level}    ...")
                        except:
                            pass
                
                if len(files) > max_files_per_dir:
                    remaining_files = len(files) - max_files_per_dir
                    structure_lines.append(f"{'  ' * level}    ... è¿˜æœ‰{remaining_files}ä¸ªæ–‡ä»¶")
                
                # æ˜¾ç¤ºç›®å½•ï¼ˆé™åˆ¶æ•°é‡ï¼‰ï¼ŒåŒ…å«å®Œæ•´è·¯å¾„
                for i, dir_item in enumerate(dirs[:max_files_per_dir]):
                    relative_path = _get_relative_path(dir_item)
                    structure_lines.append(f"{'  ' * level}ğŸ“ {relative_path}/")
                    
                    # æ·±å…¥æ¢ç´¢ç›®å½•
                    if i < 5:  # æ¢ç´¢å‰5ä¸ªç›®å½•
                        _explore_directory(dir_item, level + 1, max_level)
                    elif i == 5 and len(dirs) > 5:
                        # å¯¹äºç¬¬6ä¸ªç›®å½•ï¼Œæ˜¾ç¤ºå…¶å†…å®¹ä½œä¸ºç¤ºä¾‹
                        try:
                            sub_items = list(dir_item.iterdir())
                            structure_lines.append(f"{'  ' * (level+1)}[ç¤ºä¾‹ç›®å½•å†…å®¹]:")
                            for j, sample_item in enumerate(sub_items[:3]):
                                if sample_item.is_file():
                                    file_size = sample_item.stat().st_size
                                    sample_relative_path = _get_relative_path(sample_item)
                                    structure_lines.append(f"{'  ' * (level+1)}ğŸ“„ {sample_relative_path} ({self._format_file_size(file_size)})")
                                    
                                    # æ˜¾ç¤ºæ–‡ä»¶å†…å®¹ç¤ºä¾‹
                                    if sample_item.suffix.lower() in ['.xyz', '.csv', '.xlsx', '.json', '.jsonl', '.txt', '.tsv']:
                                        try:
                                            with open(sample_item, 'r', encoding='utf-8', errors='ignore') as f:
                                                first_lines = f.readlines()[:3]
                                            structure_lines.append(f"{'  ' * (level+1)}    [å†…å®¹ç¤ºä¾‹]:")
                                            for line in first_lines:
                                                structure_lines.append(f"{'  ' * (level+1)}    {line.strip()}")
                                        except:
                                            pass
                                else:
                                    sample_relative_path = _get_relative_path(sample_item)
                                    structure_lines.append(f"{'  ' * (level+1)}ğŸ“ {sample_relative_path}/")
                            if len(sub_items) > 3:
                                structure_lines.append(f"{'  ' * (level+1)}    ... ç­‰å…±{len(sub_items)}ä¸ªé¡¹ç›®")
                        except:
                            pass
                
                if len(dirs) > max_files_per_dir:
                    remaining_dirs = len(dirs) - max_files_per_dir
                    structure_lines.append(f"{'  ' * level}    ... è¿˜æœ‰{remaining_dirs}ä¸ªç›®å½•")
                    
            except Exception as e:
                structure_lines.append(f"{'  ' * level}(æ— æ³•è¯»å–ç›®å½•å†…å®¹: {str(e)})")
        
        try:
            _explore_directory(path)
        except Exception as e:
            structure_lines.append(f"è¯»å–ç›®å½•å¤±è´¥: {str(e)}")
        
        return "\n".join(structure_lines)
    
    def _format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
        if size_bytes < 1024:
            return f"{size_bytes}B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes/1024:.1f}KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes/(1024*1024):.1f}MB"
        else:
            return f"{size_bytes/(1024*1024*1024):.1f}GB"
    
    def _build_structure_analysis_prompt(self, structure_summary: str) -> str:
        """æ„å»ºæ–‡ä»¶ç»“æ„åˆ†æçš„prompt"""
        return build_structure_analysis_prompt(structure_summary)
    
    def _parse_structure_analysis(self, response: str) -> Dict[str, str]:
        """è§£æLLMçš„æ–‡ä»¶ç»“æ„åˆ†æå“åº”"""
        analysis = {
            "train_files": "",
            "test_files": "",
            "validation_files": "",
            "additional_files": "",
            "data_format": "",
            "loading_suggestions": ""
        }
        
        lines = response.strip().split('\n')
        current_key = None
        current_content = []
        
        for line in lines:
            line = line.strip()
            
            # å¤„ç†markdownæ ¼å¼çš„æ ‡é¢˜
            if "è®­ç»ƒé›†æ–‡ä»¶" in line and (":" in line or "**" in line):
                if current_key and current_content:
                    analysis[current_key] = "\n".join(current_content).strip()
                current_key = "train_files"
                current_content = []
                # æå–å†’å·åçš„å†…å®¹
                if ":" in line:
                    content = line.split(":", 1)[-1].strip()
                    if content:
                        current_content.append(content)
                        
            elif "æµ‹è¯•é›†æ–‡ä»¶" in line and (":" in line or "**" in line):
                if current_key and current_content:
                    analysis[current_key] = "\n".join(current_content).strip()
                current_key = "test_files"
                current_content = []
                if ":" in line:
                    content = line.split(":", 1)[-1].strip()
                    if content:
                        current_content.append(content)
                        
            elif "éªŒè¯é›†æ–‡ä»¶" in line and (":" in line or "**" in line):
                if current_key and current_content:
                    analysis[current_key] = "\n".join(current_content).strip()
                current_key = "validation_files"
                current_content = []
                if ":" in line:
                    content = line.split(":", 1)[-1].strip()
                    if content:
                        current_content.append(content)
                        
            elif "é¢å¤–æ–‡ä»¶" in line and (":" in line or "**" in line):
                if current_key and current_content:
                    analysis[current_key] = "\n".join(current_content).strip()
                current_key = "additional_files"
                current_content = []
                if ":" in line:
                    content = line.split(":", 1)[-1].strip()
                    if content:
                        current_content.append(content)
                        
            elif "æ•°æ®æ ¼å¼" in line and (":" in line or "**" in line):
                if current_key and current_content:
                    analysis[current_key] = "\n".join(current_content).strip()
                current_key = "data_format"
                current_content = []
                if ":" in line:
                    content = line.split(":", 1)[-1].strip()
                    if content:
                        current_content.append(content)
                        
            elif "åŠ è½½å»ºè®®" in line and (":" in line or "**" in line):
                if current_key and current_content:
                    analysis[current_key] = "\n".join(current_content).strip()
                current_key = "loading_suggestions"
                current_content = []
                if ":" in line:
                    content = line.split(":", 1)[-1].strip()
                    if content:
                        current_content.append(content)
                        
            elif current_key and line and not line.startswith("**") and line != "":
                # æ·»åŠ å†…å®¹è¡Œåˆ°å½“å‰å­—æ®µ
                current_content.append(line)
        
        # å¤„ç†æœ€åä¸€ä¸ªå­—æ®µ
        if current_key and current_content:
            analysis[current_key] = "\n".join(current_content).strip()
        
        return analysis
    
    def _extract_python_code(self, response: str) -> str:
        """ä»LLMå“åº”ä¸­æå–Pythonä»£ç """
        lines = response.split('\n')
        code_lines = []
        in_code_block = False
        
        for line in lines:
            if line.strip().startswith('```python') or line.strip().startswith('```Python'):
                in_code_block = True
                continue
            elif line.strip().startswith('```') and in_code_block:
                break
            elif in_code_block:
                code_lines.append(line)
        
        if not code_lines:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾å…¶ä»–æ ¼å¼
            for line in lines:
                if line.strip().startswith('```'):
                    in_code_block = not in_code_block
                    continue
                elif in_code_block:
                    code_lines.append(line)
        
        if not code_lines:
            # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œè¿”å›æ•´ä¸ªå“åº”çš„å¯èƒ½ä»£ç éƒ¨åˆ†
            self.logger.warning("æœªæ‰¾åˆ°æ ‡å‡†ä»£ç å—ï¼Œå°è¯•æå–æ•´ä¸ªå“åº”")
            return response.strip()
        
        return '\n'.join(code_lines)
    
    async def _auto_fix_code_issues(
        self,
        workspace_dir: Path,
        research_test_result: Dict,
        research_topic: str,
        research_goal: str,
        init_analysis_result: Dict,
        test_result: Dict,
        submission_file_name: str,
        current_regeneration_count: int = 0,
        max_debug_retries: int = 3,
        max_install_attempts: int = 3,
        max_regeneration: int = 3
    ) -> Dict:
        """
        è‡ªåŠ¨ä¿®å¤ä»£ç é—®é¢˜çš„å®Œæ•´å¾ªç¯é€»è¾‘ï¼ˆæå–è‡ªrun_research_taskï¼‰
        åŒ…æ‹¬ä¾èµ–å®‰è£…ã€ä»£ç debugã€ä»¥åŠdebugå¤±è´¥åçš„é‡æ–°ç”Ÿæˆ

        Args:
            workspace_dir: å·¥ä½œç›®å½•
            research_test_result: ç ”ç©¶ä»£ç æµ‹è¯•ç»“æœ
            research_topic: ç ”ç©¶ä¸»é¢˜
            research_goal: ç ”ç©¶ç›®æ ‡
            init_analysis_result: åˆæ­¥åˆ†æç»“æœ
            test_result: æµ‹è¯•ç»“æœï¼ˆåŒ…å«data_structure_infoï¼‰
            submission_file_name: æäº¤æ–‡ä»¶å
            current_regeneration_count: å½“å‰å·²é‡æ–°ç”Ÿæˆæ¬¡æ•°ï¼ˆä¸å®Œæ•´è¿è¡Œå¤±è´¥å…±äº«ï¼‰
            max_debug_retries: æ¯æ¬¡ä»£ç çš„æœ€å¤§debugå°è¯•æ¬¡æ•°
            max_install_attempts: æœ€å¤§ä¾èµ–å®‰è£…å°è¯•æ¬¡æ•°
            max_regeneration: å…¨å±€æœ€å¤§é‡æ–°ç”Ÿæˆæ¬¡æ•°

        Returns:
            Dict containing:
                - final_test_result: æœ€ç»ˆæµ‹è¯•ç»“æœ
                - install_attempts: ä¾èµ–å®‰è£…å°è¯•æ¬¡æ•°
                - debug_retry_count: debugé‡è¯•æ¬¡æ•°
                - regeneration_count: é‡æ–°ç”Ÿæˆæ¬¡æ•°
        """
        retry_count = 0
        install_attempts = 0
        regeneration_count = current_regeneration_count

        while retry_count < max_debug_retries and research_test_result['status'] == 'error':
            # æ£€æŸ¥æ˜¯å¦æ˜¯ModuleNotFoundError
            error_message = research_test_result.get('detailed_error', '')
            is_module_error = 'ModuleNotFoundError' in error_message or 'No module named' in error_message

            if is_module_error and install_attempts < max_install_attempts:
                # å°è¯•å®‰è£…ç¼ºå¤±çš„åŒ…
                install_attempts += 1
                self.logger.info(f"æ£€æµ‹åˆ°ModuleNotFoundErrorï¼Œå°è¯•è‡ªåŠ¨å®‰è£…ä¾èµ– ({install_attempts}/{max_install_attempts})...")
                self.logger.error("=" * 80)
                self.logger.error("ç¼ºå¤±ä¾èµ–é”™è¯¯:")
                self.logger.error(error_message)
                self.logger.error("=" * 80)

                # è°ƒç”¨CodingAgentå®‰è£…ä¾èµ–
                install_result = await self.coding_agent.install_missing_package(
                    error_message=error_message,
                    project_root=str(self.workspace_root.parent)  # é¡¹ç›®æ ¹ç›®å½•
                )

                if install_result['status'] == 'success':
                    self.logger.info(f"æˆåŠŸå®‰è£…: {install_result.get('package_name')}")
                    # ç›´æ¥é‡æ–°æµ‹è¯•ï¼Œä¸è®¡å…¥debugæ¬¡æ•°
                    research_test_result = await self._test_research_code(workspace_dir)
                    self.logger.info(f"å®‰è£…ä¾èµ–åé‡æ–°æµ‹è¯•: {research_test_result['status']}")

                    if research_test_result['status'] == 'success':
                        self.logger.info("å®‰è£…ä¾èµ–åä»£ç æ‰§è¡ŒæˆåŠŸï¼")
                        break
                else:
                    self.logger.error(f"ä¾èµ–å®‰è£…å¤±è´¥: {install_result.get('error')}")
                    # å¦‚æœè¾¾åˆ°æœ€å¤§å®‰è£…å°è¯•æ¬¡æ•°ï¼Œè¿›å…¥æ­£å¸¸debugæµç¨‹
                    if install_attempts >= max_install_attempts:
                        self.logger.error(f"å·²è¾¾åˆ°æœ€å¤§ä¾èµ–å®‰è£…å°è¯•æ¬¡æ•°({max_install_attempts})ï¼Œè¿›å…¥ä»£ç è°ƒè¯•æµç¨‹")

            # ä¸æ˜¯ä¾èµ–é—®é¢˜æˆ–å·²ç»å°è¯•å®‰è£…å¤šæ¬¡ï¼Œè¿›å…¥æ­£å¸¸debugæµç¨‹
            if not is_module_error or install_attempts >= max_install_attempts:
                retry_count += 1
                self.logger.info(f"Debugå°è¯• {retry_count}/{max_debug_retries}...")
                # æ‰“å°è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                self.logger.error("=" * 80)
                self.logger.error("é”™è¯¯è¯¦æƒ…:")
                self.logger.error(error_message)
                self.logger.error("=" * 80)

                debug_result = await self._debug_research_code_with_retry(
                    workspace_dir, research_test_result['detailed_error']
                )

                if debug_result['status'] == 'success':
                    # é‡æ–°æµ‹è¯•ä¿®å¤åçš„ä»£ç 
                    research_test_result = await self._test_research_code(workspace_dir)
                    self.logger.info(f"ä¿®å¤åç ”ç©¶ä»£ç æµ‹è¯•: {research_test_result['status']}")

                    if research_test_result['status'] == 'success':
                        self.logger.info("ç ”ç©¶ä»£ç debugæˆåŠŸï¼Œä»£ç å¯æ­£å¸¸è¿è¡Œ")
                        break
                else:
                    self.logger.error(f"Debugå¤±è´¥: {debug_result.get('message', '')}")

        # Debugå¤±è´¥åï¼Œå¦‚æœè¿˜æœ‰é‡æ–°ç”Ÿæˆæœºä¼šï¼Œåˆ™é‡æ–°ç”Ÿæˆä»£ç 
        if research_test_result['status'] == 'error':
            self.logger.error(f"ç»è¿‡{max_debug_retries}æ¬¡debugå°è¯•å’Œ{install_attempts}æ¬¡ä¾èµ–å®‰è£…åï¼Œç ”ç©¶ä»£ç ä»ç„¶å¤±è´¥")

            # æ£€æŸ¥æ˜¯å¦è¿˜èƒ½é‡æ–°ç”Ÿæˆ
            if regeneration_count < max_regeneration:
                regeneration_count += 1
                self.logger.info("=" * 80)
                self.logger.info(f"=== ç¬¬ {regeneration_count} æ¬¡é‡æ–°ç”Ÿæˆresearch.pyï¼ˆdebugå¤±è´¥ï¼‰===")
                self.logger.info(f"å¤±è´¥åŸå› : {research_test_result.get('message', '')}")
                self.logger.info("=" * 80)

                # æ„å»ºé”™è¯¯æç¤º
                error_output = research_test_result.get('detailed_error', '')
                regeneration_hint = f"""
**å‰ä¸€ç‰ˆæœ¬ä»£ç å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆ**ï¼š
å‰ä¸€ç‰ˆæœ¬ä»£ç ç»è¿‡{max_debug_retries}æ¬¡debugå°è¯•ä»ç„¶å¤±è´¥ï¼Œå¯èƒ½ä»£ç é€»è¾‘ä»æ ¹æœ¬ä¸Šæœ‰é—®é¢˜ã€‚

é”™è¯¯ä¿¡æ¯ï¼š
{error_output[-1000:] if len(error_output) > 1000 else error_output}

è¯·é‡æ–°åˆ†æä»»åŠ¡éœ€æ±‚ï¼Œç”Ÿæˆå…¨æ–°çš„ã€æ›´å¯é çš„ä»£ç å®ç°ã€‚
"""

                # é‡æ–°ç”Ÿæˆä»£ç ï¼Œå¸¦ä¸Šé”™è¯¯æç¤º
                regenerated_init_analysis = init_analysis_result['analysis_content'] + "\n\n" + regeneration_hint

                research_code_result = await self._generate_research_code(
                    research_topic=research_topic,
                    research_goal=research_goal,
                    init_analysis=regenerated_init_analysis,
                    data_structure_info=test_result['data_structure_info'],
                    submission_file_name=submission_file_name,
                    workspace_dir=workspace_dir
                )

                if research_code_result['status'] == 'success':
                    # æµ‹è¯•æ–°ç”Ÿæˆçš„ä»£ç 
                    research_test_result = await self._test_research_code(workspace_dir)
                    self.logger.info(f"é‡æ–°ç”Ÿæˆåç ”ç©¶ä»£ç æµ‹è¯•: {research_test_result['status']}")

                    if research_test_result['status'] == 'success':
                        self.logger.info("=" * 80)
                        self.logger.info(f"=== ç¬¬ {regeneration_count} æ¬¡é‡æ–°ç”Ÿæˆåæµ‹è¯•æˆåŠŸ ===")
                        self.logger.info("=" * 80)
                    else:
                        # æ–°ç”Ÿæˆçš„ä»£ç ä»ç„¶å¤±è´¥ï¼Œé€’å½’è°ƒç”¨è¿›è¡Œdebugæˆ–å†æ¬¡é‡æ–°ç”Ÿæˆ
                        self.logger.warning("é‡æ–°ç”Ÿæˆçš„ä»£ç ä»ç„¶å¤±è´¥ï¼Œç»§ç»­å°è¯•ä¿®å¤...")
                        return await self._auto_fix_code_issues(
                            workspace_dir=workspace_dir,
                            research_test_result=research_test_result,
                            research_topic=research_topic,
                            research_goal=research_goal,
                            init_analysis_result=init_analysis_result,
                            test_result=test_result,
                            submission_file_name=submission_file_name,
                            current_regeneration_count=regeneration_count,
                            max_debug_retries=max_debug_retries,
                            max_install_attempts=max_install_attempts,
                            max_regeneration=max_regeneration
                        )
                else:
                    self.logger.error(f"é‡æ–°ç”Ÿæˆä»£ç å¤±è´¥: {research_code_result.get('message', '')}")
            else:
                self.logger.error(f"å·²è¾¾åˆ°æœ€å¤§é‡æ–°ç”Ÿæˆæ¬¡æ•°({max_regeneration})ï¼Œæ— æ³•ç»§ç»­ä¿®å¤")

        return {
            'final_test_result': research_test_result,
            'install_attempts': install_attempts,
            'debug_retry_count': retry_count,
            'regeneration_count': regeneration_count
        }

    async def _optimize_and_retry_full_run(
        self,
        workspace_dir: Path,
        full_run_result: Dict,
        research_topic: str,
        research_goal: str,
        init_analysis_result: Dict,
        test_result: Dict,
        submission_file_name: str,
        dataset_name: str,
        benchmark_name: str,
        current_regeneration_count: int = 0,
        max_regeneration: int = 3
    ) -> Dict:
        """
        å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥åçš„ä¼˜åŒ–é‡è¯•å¾ªç¯ï¼ˆæå–è‡ªrun_research_taskï¼‰

        Args:
            workspace_dir: å·¥ä½œç›®å½•
            full_run_result: å®Œæ•´æ•°æ®é›†è¿è¡Œç»“æœ
            research_topic: ç ”ç©¶ä¸»é¢˜
            research_goal: ç ”ç©¶ç›®æ ‡
            init_analysis_result: åˆæ­¥åˆ†æç»“æœ
            test_result: æµ‹è¯•ç»“æœ
            submission_file_name: æäº¤æ–‡ä»¶å
            dataset_name: æ•°æ®é›†åç§°
            benchmark_name: benchmarkåç§°
            current_regeneration_count: å½“å‰å·²é‡æ–°ç”Ÿæˆæ¬¡æ•°ï¼ˆä¸debugå¤±è´¥å…±äº«ï¼‰
            max_regeneration: å…¨å±€æœ€å¤§é‡æ–°ç”Ÿæˆæ¬¡æ•°

        Returns:
            Dict containing:
                - final_full_run_result: æœ€ç»ˆå®Œæ•´è¿è¡Œç»“æœ
                - regeneration_count: é‡æ–°ç”Ÿæˆæ¬¡æ•°
        """
        regeneration_count = current_regeneration_count

        while regeneration_count < max_regeneration and full_run_result['status'] == 'error':
            regeneration_count += 1

            # åˆ†æå¤±è´¥åŸå› 
            failure_message = full_run_result.get('message', '')
            error_output = full_run_result.get('stderr', '') + '\n' + full_run_result.get('stdout', '')

            # æ„å»ºä¼˜åŒ–æç¤º
            optimization_hint = ""
            if 'è¶…æ—¶' in failure_message or 'timeout' in failure_message.lower():
                optimization_hint = """
ä»£ç æ‰§è¡Œè¶…æ—¶ï¼ˆ2å°æ—¶é™åˆ¶ï¼‰ã€‚è¯·ä¼˜åŒ–ä»£ç ä»¥æé«˜è¿è¡Œé€Ÿåº¦ï¼š
1. å‡å°‘ç‰¹å¾æ•°é‡ï¼ˆå¦‚TF-IDFçš„max_featuresä»5000é™åˆ°1000-2000ï¼‰
2. ä½¿ç”¨æ›´ç®€å•çš„æ¨¡å‹ï¼ˆå¦‚LogisticRegressionè€Œéå¤æ‚çš„é›†æˆæ¨¡å‹ï¼‰
3. å‡å°‘è®­ç»ƒæ•°æ®é‡ï¼ˆå¦‚ä½¿ç”¨stratified samplingå–å­é›†ï¼‰
4. ç§»é™¤è€—æ—¶çš„ç‰¹å¾å·¥ç¨‹æ­¥éª¤
5. é¿å…ä½¿ç”¨å¾ªç¯éå†æ•°æ®ï¼Œä½¿ç”¨å‘é‡åŒ–æ“ä½œ
6. ç¡®ä¿ä½¿ç”¨n_jobs=-1ç­‰å¹¶è¡Œå‚æ•°åŠ é€Ÿè®­ç»ƒ
"""
            elif 'memory' in failure_message.lower() or 'oom' in failure_message.lower():
                optimization_hint = """
å†…å­˜ä¸è¶³é”™è¯¯ã€‚è¯·ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼š
1. å‡å°‘TF-IDFç‰¹å¾æ•°é‡ï¼ˆmax_featuresé™ä½åˆ°1000ä»¥ä¸‹ï¼‰
2. ä½¿ç”¨sparse matrixè€Œédense matrix
3. åˆ†æ‰¹å¤„ç†æ•°æ®è€Œéä¸€æ¬¡æ€§åŠ è½½
4. ä½¿ç”¨å†…å­˜é«˜æ•ˆçš„æ¨¡å‹ï¼ˆLinearSVC, SGDClassifierç­‰ï¼‰
5. åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„ä¸­é—´å˜é‡
"""
            else:
                optimization_hint = f"""
å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š
{error_output[-1000:] if len(error_output) > 1000 else error_output}

è¯·åˆ†æé”™è¯¯å¹¶ä¼˜åŒ–ä»£ç ï¼Œç¡®ä¿èƒ½åœ¨2å°æ—¶å†…å®Œæˆè®­ç»ƒã€‚
"""

            self.logger.info("=" * 80)
            self.logger.info(f"=== ç¬¬ {regeneration_count} æ¬¡é‡æ–°ç”Ÿæˆresearch.pyï¼ˆå®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥ï¼‰===")
            self.logger.info(f"å¤±è´¥åŸå› : {failure_message}")
            self.logger.info("=" * 80)

            # é‡æ–°ç”Ÿæˆä»£ç ï¼Œå¸¦ä¸Šä¼˜åŒ–æç¤º
            optimized_init_analysis = init_analysis_result['analysis_content'] + "\n\n**é‡è¦ä¼˜åŒ–è¦æ±‚**ï¼š" + optimization_hint

            research_code_result = await self._generate_research_code(
                research_topic=research_topic,
                research_goal=research_goal,
                init_analysis=optimized_init_analysis,
                data_structure_info=test_result['data_structure_info'],
                submission_file_name=submission_file_name,
                workspace_dir=workspace_dir
            )

            if research_code_result['status'] == 'success':
                # æµ‹è¯•æ–°ä»£ç 
                research_test_result = await self._test_research_code(workspace_dir)

                if research_test_result['status'] == 'success':
                    # é‡æ–°è¿è¡Œå®Œæ•´æ•°æ®é›†
                    full_run_result = await self._run_full_research_code(workspace_dir)

                    if full_run_result['status'] == 'success':
                        self.logger.info("=" * 80)
                        self.logger.info(f"=== ç¬¬ {regeneration_count} æ¬¡ä¼˜åŒ–åå®Œæ•´è¿è¡ŒæˆåŠŸ ===")
                        self.logger.info("=" * 80)

                        # è¯„ä¼°ç»“æœ
                        evaluation_result = await self._evaluate_submission(
                            workspace_dir,
                            dataset_name,
                            benchmark_name
                        )
                        full_run_result['evaluation'] = evaluation_result

                        # å®æ—¶è¾“å‡ºè¯„ä¼°ç»“æœ
                        if evaluation_result['status'] == 'success':
                            self.logger.info("=" * 80)
                            self.logger.info("=== è¯„ä¼°ç»“æœ ===")
                            self.logger.info(f"åˆ†æ•°: {evaluation_result.get('score', 'N/A')}")
                            self.logger.info(f"é‡‘ç‰Œ: {'æ˜¯' if evaluation_result.get('gold_medal') else 'å¦'}")
                            self.logger.info(f"é“¶ç‰Œ: {'æ˜¯' if evaluation_result.get('silver_medal') else 'å¦'}")
                            self.logger.info(f"é“œç‰Œ: {'æ˜¯' if evaluation_result.get('bronze_medal') else 'å¦'}")
                            self.logger.info(f"è¶…è¿‡ä¸­ä½æ•°: {'æ˜¯' if evaluation_result.get('above_median') else 'å¦'}")
                            self.logger.info(f"æäº¤æœ‰æ•ˆ: {'æ˜¯' if evaluation_result.get('valid_submission') else 'å¦'}")
                            self.logger.info(evaluation_result.get('message', ''))
                            self.logger.info("=" * 80)
                        break
                    else:
                        self.logger.error(f"ç¬¬ {regeneration_count} æ¬¡ä¼˜åŒ–åå®Œæ•´è¿è¡Œä»ç„¶å¤±è´¥: {full_run_result.get('message', '')}")
                else:
                    self.logger.error(f"ç¬¬ {regeneration_count} æ¬¡ä¼˜åŒ–åçš„ä»£ç æµ‹è¯•å¤±è´¥")
                    # æµ‹è¯•å¤±è´¥ä¹Ÿè¦ç»§ç»­é‡è¯•ï¼Œä¸è¦break
            else:
                self.logger.error(f"ç¬¬ {regeneration_count} æ¬¡é‡æ–°ç”Ÿæˆresearch.pyå¤±è´¥")
                break

        if regeneration_count >= max_regeneration and full_run_result['status'] == 'error':
            self.logger.error(f"å·²è¾¾åˆ°æœ€å¤§é‡æ–°ç”Ÿæˆæ¬¡æ•° ({max_regeneration})ï¼Œå®Œæ•´è¿è¡Œä»ç„¶å¤±è´¥")

        return {
            'final_full_run_result': full_run_result,
            'regeneration_count': regeneration_count
        }

    async def _debug_data_loader_with_retry(self, workspace_dir: Path, error_message: str) -> Dict[str, str]:
        """
        ä½¿ç”¨CodingAgentè°ƒè¯•ä¿®å¤æ•°æ®åŠ è½½ä»£ç 
        
        Args:
            workspace_dir: å·¥ä½œç›®å½•
            error_message: é”™è¯¯ä¿¡æ¯
            
        Returns:
            è°ƒè¯•ç»“æœ
        """
        try:
            loader_file = workspace_dir / "load_research_data.py"
            if not loader_file.exists():
                return {
                    "status": "error",
                    "message": "æ•°æ®åŠ è½½æ–‡ä»¶ä¸å­˜åœ¨"
                }
            
            self.logger.info("å¼€å§‹è°ƒè¯•æ•°æ®åŠ è½½ä»£ç ...")
            
            # è°ƒç”¨CodingAgentçš„debug_codeåŠŸèƒ½
            debug_result = await self.coding_agent.debug_code(
                code_path=str(loader_file),
                error_message=error_message,
                error_context="æ•°æ®åŠ è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œå¯èƒ½éœ€è¦å¤„ç†æ•°æ®ç±»å‹ã€ç¼ºå¤±å€¼æˆ–æ–‡ä»¶è·¯å¾„é—®é¢˜"
            )
            
            if debug_result['status'] == 'success':
                self.logger.info("æ•°æ®åŠ è½½ä»£ç è°ƒè¯•ä¿®å¤æˆåŠŸ")
                return {
                    "status": "success",
                    "message": "ä»£ç ä¿®å¤æˆåŠŸ"
                }
            else:
                self.logger.error(f"æ•°æ®åŠ è½½ä»£ç è°ƒè¯•å¤±è´¥: {debug_result.get('error', '')}")
                return {
                    "status": "error",
                    "message": f"ä»£ç è°ƒè¯•å¤±è´¥: {debug_result.get('error', '')}"
                }
                
        except Exception as e:
            self.logger.error(f"è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "message": f"è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {str(e)}"
            }
    
    def _get_submission_file_name(self, structure_info: Dict[str, str], benchmark_name: str = "mlebench") -> str:
        """
        ä»æ–‡ä»¶ç»“æ„ä¿¡æ¯ä¸­è·å–æäº¤æ–‡ä»¶å

        Args:
            structure_info: æ–‡ä»¶ç»“æ„ä¿¡æ¯
            benchmark_name: benchmarkåç§°

        Returns:
            æäº¤æ–‡ä»¶å
        """
        structure_summary = structure_info.get('structure_summary', '')
        analysis_result = structure_info.get('analysis_result', {})

        # ä»ç»“æ„æ‘˜è¦ä¸­æŸ¥æ‰¾submissionç›¸å…³æ–‡ä»¶
        if 'sample_submission' in structure_summary.lower() or 'submission' in structure_summary.lower():
            lines = structure_summary.split('\n')
            for line in lines:
                if 'submission' in line.lower():
                    # æ”¯æŒå¤šç§æ ¼å¼
                    for ext in ['.csv', '.xlsx', '.json', '.jsonl', '.txt']:
                        if ext in line.lower():
                            parts = line.split()
                            for part in parts:
                                if 'submission' in part.lower() and ext in part.lower():
                                    return part.split('/')[-1]  # åªè¦æ–‡ä»¶åéƒ¨åˆ†

        # ä»é¢å¤–æ–‡ä»¶ä¸­æŸ¥æ‰¾
        additional_files = analysis_result.get('additional_files', '')
        if 'submission' in additional_files.lower():
            # æ£€æŸ¥å¤šç§æ ¼å¼
            for ext in ['.csv', '.xlsx', '.json', '.jsonl', '.txt']:
                if f'submission{ext}' in additional_files.lower():
                    # æå–å®Œæ•´æ–‡ä»¶å
                    import re
                    pattern = rf'\S*submission\S*{ext}'
                    match = re.search(pattern, additional_files.lower())
                    if match:
                        return match.group(0)

        # æ ¹æ®benchmarkç±»å‹è¿”å›é»˜è®¤æäº¤æ–‡ä»¶å
        benchmark_submission_files = {
            "mlebench": "sample_submission.csv",
            "kaggle": "submission.csv",
            "default": "submission.csv"
        }

        return benchmark_submission_files.get(benchmark_name.lower(), benchmark_submission_files["default"])
    
    async def _generate_research_code(
        self,
        research_topic: str,
        research_goal: str,
        init_analysis: str,
        data_structure_info: str,
        submission_file_name: str,
        workspace_dir: Path
    ) -> Dict[str, str]:
        """
        ç”Ÿæˆç ”ç©¶ä»£ç 
        
        Args:
            research_topic: ç ”ç©¶ä¸»é¢˜
            research_goal: ç ”ç©¶ç›®æ ‡
            init_analysis: åˆæ­¥åˆ†æç»“æœ
            data_structure_info: æ•°æ®ç»“æ„ä¿¡æ¯
            submission_file_name: æäº¤æ–‡ä»¶å
            workspace_dir: å·¥ä½œç›®å½•
            
        Returns:
            ç”Ÿæˆç»“æœ
        """
        try:
            result = await self.coding_agent.generate_research_code(
                research_topic=research_topic,
                research_goal=research_goal,
                init_analysis=init_analysis,
                data_structure_info=data_structure_info,
                submission_file_name=submission_file_name,
                workspace_dir=str(workspace_dir),
                device_info=self.device_info
            )
            return result
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆç ”ç©¶ä»£ç æ—¶å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"ç”Ÿæˆç ”ç©¶ä»£ç å¤±è´¥: {str(e)}"
            }
    
    def _execute_research_code(
        self,
        workspace_dir: Path,
        timeout: int,
        use_small_sample: bool = False
    ) -> subprocess.CompletedProcess:
        """æ‰§è¡Œresearch.pyä»£ç 

        Args:
            workspace_dir: å·¥ä½œç›®å½•
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            use_small_sample: æ˜¯å¦ä½¿ç”¨å°æ ·æœ¬æ¨¡å¼

        Returns:
            subprocess.CompletedProcesså¯¹è±¡
        """
        env = os.environ.copy()
        env["PYTHONUNBUFFERED"] = "1"

        if use_small_sample:
            env["USE_SMALL_SAMPLE"] = "1"
            env["QUICK_TEST"] = "1"
        else:
            # å®Œæ•´è¿è¡Œæ—¶ï¼Œç§»é™¤å°æ ·æœ¬ç¯å¢ƒå˜é‡
            env.pop("USE_SMALL_SAMPLE", None)
            env.pop("QUICK_TEST", None)

        result = subprocess.run(
            ["python", "-u", "research.py"],
            cwd=str(workspace_dir),
            capture_output=True,
            text=True,
            timeout=timeout,
            env=env
        )

        return result

    def _validate_csv_files(self, workspace_dir: Path) -> tuple:
        """éªŒè¯workspaceä¸­çš„CSVæ–‡ä»¶

        Args:
            workspace_dir: å·¥ä½œç›®å½•

        Returns:
            (valid_files, all_files): æœ‰æ•ˆæ–‡ä»¶åˆ—è¡¨å’Œæ‰€æœ‰æ–‡ä»¶åˆ—è¡¨
        """
        import pandas as pd

        submission_files = list(workspace_dir.glob("*.csv"))
        valid_files = []

        for csv_file in submission_files:
            try:
                df = pd.read_csv(csv_file)
                # æ£€æŸ¥æ–‡ä»¶ä¸æ˜¯ç©ºçš„ï¼Œä¸”æœ‰å®é™…æ•°æ®è¡Œ
                if len(df) > 0 and not df.empty:
                    # æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰1åˆ—æ•°æ®
                    if len(df.columns) >= 1:
                        valid_files.append(csv_file)
                        self.logger.info(f"æœ‰æ•ˆsubmissionæ–‡ä»¶: {csv_file.name}, å½¢çŠ¶: {df.shape}")
                    else:
                        self.logger.warning(f"submissionæ–‡ä»¶åˆ—æ•°ä¸è¶³: {csv_file.name}")
                else:
                    self.logger.warning(f"submissionæ–‡ä»¶ä¸ºç©º: {csv_file.name}")
            except Exception as e:
                self.logger.warning(f"æ— æ³•è¯»å–submissionæ–‡ä»¶ {csv_file.name}: {e}")

        return valid_files, submission_files

    def _find_and_validate_output_files(self, workspace_dir: Path, benchmark_name: str = "mlebench") -> tuple:
        """
        æŸ¥æ‰¾å¹¶éªŒè¯è¾“å‡ºæ–‡ä»¶

        Args:
            workspace_dir: å·¥ä½œç›®å½•
            benchmark_name: benchmarkåç§°

        Returns:
            (valid_files, all_files): æœ‰æ•ˆæ–‡ä»¶åˆ—è¡¨å’Œæ‰€æœ‰æ‰¾åˆ°çš„æ–‡ä»¶åˆ—è¡¨
        """
        import pandas as pd

        # æ ¹æ®benchmarkç±»å‹å†³å®šæ£€æŸ¥å“ªäº›æ ¼å¼
        benchmark_file_patterns = {
            "mlebench": ["*.csv"],  # mlebenchä¸»è¦ä½¿ç”¨CSVæ ¼å¼
            "kaggle": ["*.csv"],
            "default": ["*.csv", "*.xlsx", "*.json", "*.jsonl", "*.txt"]  # å…¶ä»–benchmarkæ”¯æŒæ›´å¤šæ ¼å¼
        }

        file_patterns = benchmark_file_patterns.get(benchmark_name.lower(), benchmark_file_patterns["default"])

        all_files = []
        for pattern in file_patterns:
            all_files.extend(workspace_dir.glob(pattern))

        valid_files = []
        for file_path in all_files:
            try:
                # æ ¹æ®æ–‡ä»¶ç±»å‹éªŒè¯
                if file_path.suffix.lower() == '.csv':
                    df = pd.read_csv(file_path)
                    if len(df) > 0 and len(df.columns) >= 1:
                        valid_files.append(file_path)
                        self.logger.info(f"æœ‰æ•ˆæ–‡ä»¶: {file_path.name}, å½¢çŠ¶: {df.shape}")
                    else:
                        self.logger.warning(f"æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ•ˆ: {file_path.name}")
                elif file_path.suffix.lower() in ['.json', '.jsonl']:
                    # JSONæ–‡ä»¶åŸºæœ¬æ£€æŸ¥
                    if file_path.stat().st_size > 0:
                        valid_files.append(file_path)
                        self.logger.info(f"æœ‰æ•ˆæ–‡ä»¶: {file_path.name}, å¤§å°: {file_path.stat().st_size}")
                elif file_path.suffix.lower() in ['.txt', '.xlsx']:
                    # å…¶ä»–æ ¼å¼åªæ£€æŸ¥æ˜¯å¦éç©º
                    if file_path.stat().st_size > 0:
                        valid_files.append(file_path)
                        self.logger.info(f"æœ‰æ•ˆæ–‡ä»¶: {file_path.name}, å¤§å°: {file_path.stat().st_size}")
            except Exception as e:
                self.logger.warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path.name}: {e}")

        return valid_files, all_files

    async def _test_research_code(self, workspace_dir: Path, benchmark_name: str = "mlebench") -> Dict[str, str]:
        """
        æµ‹è¯•ç ”ç©¶ä»£ç 

        Args:
            workspace_dir: å·¥ä½œç›®å½•
            benchmark_name: benchmarkåç§°

        Returns:
            æµ‹è¯•ç»“æœ
        """
        try:
            research_file = workspace_dir / "research.py"
            if not research_file.exists():
                return {
                    "status": "error",
                    "error": "ç ”ç©¶ä»£ç æ–‡ä»¶ä¸å­˜åœ¨",
                    "message": "research.pyæ–‡ä»¶æœªæ‰¾åˆ°",
                    "detailed_error": "research.pyæ–‡ä»¶æœªæ‰¾åˆ°"
                }
            
            self.logger.info("æ‰§è¡Œç ”ç©¶ä»£ç æµ‹è¯•ï¼ˆå°æ ·æœ¬å¿«é€ŸéªŒè¯æ¨¡å¼ï¼‰...")
            
            # æ‰§è¡ŒPythonè„šæœ¬
            result = subprocess.run(
                ["python", "-u", "research.py"],
                cwd=str(workspace_dir),
                capture_output=True,
                text=True,
                timeout=600,  # 10åˆ†é’Ÿè¶…æ—¶
                env={**os.environ, "PYTHONUNBUFFERED": "1", "USE_SMALL_SAMPLE": "1", "QUICK_TEST": "1"}
            )
            
            # åˆå¹¶è¾“å‡º
            full_output = ""
            if result.stdout:
                full_output += result.stdout
            if result.stderr:
                full_output += "\n=== STDERR ===\n" + result.stderr
            
            if result.returncode == 0:
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸç”Ÿæˆäº†æœ‰æ•ˆçš„.csvæ–‡ä»¶
                submission_files = list(workspace_dir.glob("*.csv"))
                
                if submission_files:
                    # éªŒè¯submissionæ–‡ä»¶çš„æœ‰æ•ˆæ€§
                    valid_files = []
                    for csv_file in submission_files:
                        try:
                            import pandas as pd
                            df = pd.read_csv(csv_file)
                            # æ£€æŸ¥æ–‡ä»¶ä¸æ˜¯ç©ºçš„ï¼Œä¸”æœ‰å®é™…æ•°æ®è¡Œ
                            if len(df) > 0 and not df.empty:
                                # æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰1åˆ—æ•°æ®
                                if len(df.columns) >= 1:
                                    valid_files.append(csv_file)
                                    self.logger.info(f"æœ‰æ•ˆsubmissionæ–‡ä»¶: {csv_file.name}, å½¢çŠ¶: {df.shape}")
                                else:
                                    self.logger.warning(f"submissionæ–‡ä»¶åˆ—æ•°ä¸è¶³: {csv_file.name}, åˆ—æ•°: {len(df.columns)}")
                            else:
                                self.logger.warning(f"submissionæ–‡ä»¶ä¸ºç©º: {csv_file.name}")
                        except Exception as e:
                            self.logger.warning(f"æ— æ³•è¯»å–submissionæ–‡ä»¶ {csv_file.name}: {e}")
                    
                    if valid_files:
                        self.logger.info(f"ç ”ç©¶ä»£ç æ‰§è¡ŒæˆåŠŸï¼Œç”Ÿæˆäº†æœ‰æ•ˆsubmissionæ–‡ä»¶: {[str(f.name) for f in valid_files]}")
                        return {
                            "status": "success",
                            "stdout": result.stdout,
                            "stderr": result.stderr,
                            "output_info": full_output,
                            "submission_files": [str(f) for f in valid_files],
                            "message": "ç ”ç©¶ä»£ç æ‰§è¡Œå®Œæˆå¹¶ç”Ÿæˆäº†æœ‰æ•ˆsubmissionæ–‡ä»¶"
                        }
                    else:
                        self.logger.warning("ç”Ÿæˆçš„.csvæ–‡ä»¶æ— æ•ˆï¼ˆç©ºæ–‡ä»¶æˆ–æ ¼å¼é”™è¯¯ï¼‰")
                        error_details = f"Exit code: {result.returncode}\nSTDOUT:\n{result.stdout}\nSTDERR:\n{result.stderr}"
                        return {
                            "status": "error",
                            "stdout": result.stdout,
                            "stderr": result.stderr,
                            "returncode": result.returncode,
                            "output_info": full_output,
                            "detailed_error": f"ç”Ÿæˆçš„.csvæ–‡ä»¶æ— æ•ˆï¼ˆç©ºæ–‡ä»¶æˆ–æ ¼å¼é”™è¯¯ï¼‰ã€‚å®Œæ•´è¾“å‡º:\n{error_details}",
                            "message": "ç ”ç©¶ä»£ç æ‰§è¡Œå¤±è´¥ï¼šç”Ÿæˆçš„submissionæ–‡ä»¶æ— æ•ˆ"
                        }
                else:
                    self.logger.warning("ç ”ç©¶ä»£ç æ‰§è¡Œå®Œæˆä½†æœªç”Ÿæˆ.csvæ–‡ä»¶")
                    # å°†å®Œæ•´è¾“å‡ºä½œä¸ºé”™è¯¯ä¿¡æ¯ï¼Œæ–¹ä¾¿debug
                    error_details = f"Exit code: {result.returncode}\nSTDOUT:\n{result.stdout}\nSTDERR:\n{result.stderr}"
                    return {
                        "status": "error",
                        "stdout": result.stdout,
                        "stderr": result.stderr,
                        "returncode": result.returncode,
                        "output_info": full_output,
                        "detailed_error": f"ä»£ç æ‰§è¡Œå®Œæˆä½†æœªç”Ÿæˆ.csvæ–‡ä»¶ã€‚å®Œæ•´è¾“å‡º:\n{error_details}",
                        "message": "ç ”ç©¶ä»£ç æ‰§è¡Œå¤±è´¥ï¼šæœªç”Ÿæˆ.csvæ–‡ä»¶"
                    }
            else:
                self.logger.error(f"ç ”ç©¶ä»£ç æ‰§è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
                # è¿”å›å®Œæ•´çš„é”™è¯¯ä¿¡æ¯ï¼ŒåŒ…æ‹¬stdoutå’Œstderr
                error_details = f"Exit code: {result.returncode}\nSTDOUT:\n{result.stdout}\nSTDERR:\n{result.stderr}"
                return {
                    "status": "error",
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode,
                    "output_info": full_output,
                    "detailed_error": error_details,
                    "message": "ç ”ç©¶ä»£ç æ‰§è¡Œå¤±è´¥"
                }
                
        except subprocess.TimeoutExpired:
            self.logger.error("ç ”ç©¶ä»£ç æ‰§è¡Œè¶…æ—¶")
            return {
                "status": "error",
                "error": "æ‰§è¡Œè¶…æ—¶",
                "message": "ç ”ç©¶ä»£ç æ‰§è¡Œè¶…æ—¶",
                "detailed_error": "æ‰§è¡Œè¶…æ—¶"
            }
        except Exception as e:
            self.logger.error(f"ç ”ç©¶ä»£ç æµ‹è¯•å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"ç ”ç©¶ä»£ç æµ‹è¯•å¤±è´¥: {str(e)}",
                "detailed_error": str(e)
            }

    async def _run_full_research_code(self, workspace_dir: Path) -> Dict[str, str]:
        """
        è¿è¡Œå®Œæ•´æ•°æ®é›†çš„ç ”ç©¶ä»£ç 

        Args:
            workspace_dir: å·¥ä½œç›®å½•

        Returns:
            è¿è¡Œç»“æœ
        """
        try:
            research_file = workspace_dir / "research.py"
            if not research_file.exists():
                return {
                    "status": "error",
                    "error": "ç ”ç©¶ä»£ç æ–‡ä»¶ä¸å­˜åœ¨",
                    "message": "research.pyæ–‡ä»¶æœªæ‰¾åˆ°"
                }

            self.logger.info("æ‰§è¡Œå®Œæ•´æ•°æ®é›†è®­ç»ƒï¼ˆç§»é™¤ç¯å¢ƒå˜é‡é™åˆ¶ï¼‰...")

            # æ‰§è¡ŒPythonè„šæœ¬ï¼Œä¸è®¾ç½®USE_SMALL_SAMPLEå’ŒQUICK_TEST
            env = os.environ.copy()
            env.pop("USE_SMALL_SAMPLE", None)
            env.pop("QUICK_TEST", None)
            env["PYTHONUNBUFFERED"] = "1"

            result = subprocess.run(
                ["python", "-u", "research.py"],
                cwd=str(workspace_dir),
                capture_output=True,
                text=True,
                timeout=7200,  # 2å°æ—¶è¶…æ—¶ï¼ˆå®Œæ•´æ•°æ®é›†å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
                env=env
            )

            # åˆå¹¶è¾“å‡º
            full_output = ""
            if result.stdout:
                full_output += result.stdout
            if result.stderr:
                full_output += "\n=== STDERR ===\n" + result.stderr

            if result.returncode == 0:
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸç”Ÿæˆäº†æœ‰æ•ˆçš„.csvæ–‡ä»¶
                submission_files = list(workspace_dir.glob("*.csv"))

                if submission_files:
                    # éªŒè¯submissionæ–‡ä»¶çš„æœ‰æ•ˆæ€§
                    valid_files = []
                    for csv_file in submission_files:
                        try:
                            import pandas as pd
                            df = pd.read_csv(csv_file)
                            # æ£€æŸ¥æ–‡ä»¶ä¸æ˜¯ç©ºçš„ï¼Œä¸”æœ‰å®é™…æ•°æ®è¡Œ
                            if len(df) > 0 and not df.empty:
                                # æ£€æŸ¥æ˜¯å¦æœ‰åˆç†çš„åˆ—
                                if len(df.columns) >= 1:
                                    valid_files.append(csv_file)
                                    self.logger.info(f"å®Œæ•´è¿è¡Œç”Ÿæˆæœ‰æ•ˆsubmission: {csv_file.name}, å½¢çŠ¶: {df.shape}")
                                else:
                                    self.logger.warning(f"submissionæ–‡ä»¶åˆ—æ•°ä¸è¶³: {csv_file.name}")
                            else:
                                self.logger.warning(f"submissionæ–‡ä»¶ä¸ºç©º: {csv_file.name}")
                        except Exception as e:
                            self.logger.warning(f"æ— æ³•è¯»å–submissionæ–‡ä»¶ {csv_file.name}: {e}")

                    if valid_files:
                        self.logger.info(f"å®Œæ•´æ•°æ®é›†è®­ç»ƒæˆåŠŸï¼Œç”Ÿæˆsubmission: {[str(f.name) for f in valid_files]}")
                        return {
                            "status": "success",
                            "stdout": result.stdout,
                            "stderr": result.stderr,
                            "submission_files": [str(f.name) for f in valid_files],
                            "message": "å®Œæ•´æ•°æ®é›†è®­ç»ƒæˆåŠŸ"
                        }
                    else:
                        self.logger.warning("å®Œæ•´è¿è¡Œç”Ÿæˆçš„.csvæ–‡ä»¶æ— æ•ˆ")
                        return {
                            "status": "error",
                            "stdout": result.stdout,
                            "stderr": result.stderr,
                            "returncode": result.returncode,
                            "message": "å®Œæ•´è¿è¡Œç”Ÿæˆçš„submissionæ–‡ä»¶æ— æ•ˆ"
                        }
                else:
                    self.logger.warning("å®Œæ•´è¿è¡Œæœªç”Ÿæˆ.csvæ–‡ä»¶")
                    return {
                        "status": "error",
                        "stdout": result.stdout,
                        "stderr": result.stderr,
                        "returncode": result.returncode,
                        "message": "å®Œæ•´è¿è¡Œæœªç”Ÿæˆ.csvæ–‡ä»¶"
                    }
            else:
                self.logger.error(f"å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
                return {
                    "status": "error",
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode,
                    "message": f"å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}"
                }

        except subprocess.TimeoutExpired:
            self.logger.error("å®Œæ•´æ•°æ®é›†è¿è¡Œè¶…æ—¶ï¼ˆ2å°æ—¶ï¼‰")
            return {
                "status": "error",
                "error": "æ‰§è¡Œè¶…æ—¶",
                "message": "å®Œæ•´æ•°æ®é›†è¿è¡Œè¶…æ—¶"
            }
        except Exception as e:
            self.logger.error(f"å®Œæ•´æ•°æ®é›†è¿è¡Œå‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥: {str(e)}"
            }

    async def _debug_research_code_with_retry(self, workspace_dir: Path, error_message: str) -> Dict[str, str]:
        """
        ä½¿ç”¨CodingAgentè°ƒè¯•ä¿®å¤ç ”ç©¶ä»£ç 
        
        Args:
            workspace_dir: å·¥ä½œç›®å½•
            error_message: é”™è¯¯ä¿¡æ¯
            
        Returns:
            è°ƒè¯•ç»“æœ
        """
        try:
            research_file = workspace_dir / "research.py"
            if not research_file.exists():
                return {
                    "status": "error",
                    "message": "ç ”ç©¶ä»£ç æ–‡ä»¶ä¸å­˜åœ¨"
                }
            
            self.logger.info("å¼€å§‹è°ƒè¯•ç ”ç©¶ä»£ç ...")
            
            # è°ƒç”¨CodingAgentçš„debug_codeåŠŸèƒ½
            debug_result = await self.coding_agent.debug_code(
                code_path=str(research_file),
                error_message=error_message,
                error_context="ç ”ç©¶ä»£ç æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œå¯èƒ½éœ€è¦å¤„ç†æ¨¡å‹è®­ç»ƒã€æ•°æ®å¤„ç†æˆ–æ–‡ä»¶è¾“å‡ºé—®é¢˜"
            )
            
            if debug_result['status'] == 'success':
                self.logger.info("ç ”ç©¶ä»£ç è°ƒè¯•ä¿®å¤æˆåŠŸ")
                return {
                    "status": "success",
                    "message": "ä»£ç ä¿®å¤æˆåŠŸ"
                }
            else:
                self.logger.error(f"ç ”ç©¶ä»£ç è°ƒè¯•å¤±è´¥: {debug_result.get('error', '')}")
                return {
                    "status": "error",
                    "message": f"ä»£ç è°ƒè¯•å¤±è´¥: {debug_result.get('error', '')}"
                }
                
        except Exception as e:
            self.logger.error(f"è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "message": f"è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {str(e)}"
            }

    async def _evaluate_submission(
        self,
        workspace_dir: Path,
        dataset_name: str,
        benchmark_name: str
    ) -> Dict:
        """
        è¯„ä¼°æäº¤ç»“æœ

        Args:
            workspace_dir: å·¥ä½œç›®å½•
            dataset_name: æ•°æ®é›†åç§°
            benchmark_name: benchmarkåç§°

        Returns:
            è¯„ä¼°ç»“æœ
        """
        try:
            self.logger.info(f"å¼€å§‹è¯„ä¼°æäº¤ç»“æœ: benchmark={benchmark_name}, dataset={dataset_name}")

            # è·å–å¯¹åº”çš„è¯„ä¼°å™¨
            evaluator = self.evaluators.get(benchmark_name.lower())

            if not evaluator:
                self.logger.warning(f"æœªæ‰¾åˆ°benchmark '{benchmark_name}' çš„è¯„ä¼°å™¨ï¼Œè·³è¿‡è¯„ä¼°")
                return {
                    "status": "skipped",
                    "message": f"æœªæ‰¾åˆ°benchmark '{benchmark_name}' çš„è¯„ä¼°å™¨",
                    "valid_submission": None
                }

            # è°ƒç”¨è¯„ä¼°å™¨
            result = await evaluator.evaluate(workspace_dir, dataset_name, benchmark_name)

            return result

        except Exception as e:
            self.logger.error(f"è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"è¯„ä¼°å¤±è´¥: {str(e)}",
                "valid_submission": False
            }

    async def init_analyzing(
        self,
        research_topic: str,
        research_goal: str,
        dataset_path: str,
        data_structure_info: str,
        structure_analysis: Dict[str, str]
    ) -> Dict[str, str]:
        """
        åˆæ­¥åˆ†æï¼šåŸºäºæ•°æ®ç»“æ„å’Œç ”ç©¶ä»»åŠ¡è¿›è¡Œåˆæ­¥åˆ†æ
        
        Args:
            research_topic: ç ”ç©¶ä¸»é¢˜
            research_goal: ç ”ç©¶ç›®æ ‡
            dataset_path: æ•°æ®é›†è·¯å¾„
            data_structure_info: æ•°æ®ç»“æ„ä¿¡æ¯ï¼ˆä»data loaderè¾“å‡ºè·å–ï¼‰
            structure_analysis: æ–‡ä»¶ç»“æ„åˆ†æç»“æœ
        
        Returns:
            åˆæ­¥åˆ†æç»“æœ
        """
        self.logger.info("å¼€å§‹è¿›è¡Œåˆæ­¥æ•°æ®å’Œä»»åŠ¡åˆ†æ...")
        
        try:
            # æ„å»ºåˆæ­¥åˆ†æprompt
            prompt = build_init_analysis_prompt(
                research_topic=research_topic,
                research_goal=research_goal,
                data_structure_info=data_structure_info,
                train_files=structure_analysis.get('train_files', ''),
                test_files=structure_analysis.get('test_files', ''),
                data_format=structure_analysis.get('data_format', '')
            )

            # è°ƒç”¨LLMè¿›è¡Œåˆæ­¥åˆ†æ
            messages = [{"role": "user", "content": prompt}]
            response = await self.client.chat(messages, max_tokens=3000)
            
            self.logger.info("=== åˆæ­¥åˆ†æç»“æœ ===")
            self.logger.info(response)
            
            return {
                "status": "success",
                "analysis_content": response,
                "message": "åˆæ­¥åˆ†æå®Œæˆ"
            }
            
        except Exception as e:
            self.logger.error(f"åˆæ­¥åˆ†æå¤±è´¥: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"åˆæ­¥åˆ†æå¤±è´¥: {str(e)}"
            }
    
    def _create_workspace(self, benchmark_name: str, dataset_name: str) -> Path:
        """åˆ›å»ºå·¥ä½œç›®å½•"""
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        exp_id = f"exp_id_{timestamp}"
        
        # åˆ›å»ºå·¥ä½œç›®å½•è·¯å¾„
        workspace_dir = self.workspace_root / benchmark_name / dataset_name / exp_id
        workspace_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"åˆ›å»ºå·¥ä½œç›®å½•: {workspace_dir}")
        return workspace_dir
    
    async def _generate_data_loader(
        self, 
        structure_info: Dict[str, str], 
        dataset_path: str, 
        workspace_dir: Path
    ) -> Dict[str, str]:
        """ç”Ÿæˆæ•°æ®åŠ è½½ä»£ç """
        try:
            # æ„å»ºæ•°æ®åŠ è½½ä»£ç ç”Ÿæˆéœ€æ±‚
            analysis_result = structure_info.get('analysis_result', {})
            structure_summary = structure_info.get('structure_summary', '')

            requirements = build_data_loader_generation_prompt(
                dataset_path=dataset_path,
                structure_summary=structure_summary,
                train_files=analysis_result.get('train_files', ''),
                test_files=analysis_result.get('test_files', ''),
                data_format=analysis_result.get('data_format', ''),
                loading_suggestions=analysis_result.get('loading_suggestions', '')
            )

            # ç›´æ¥è°ƒç”¨LLMç”Ÿæˆä»£ç ï¼Œä¸é€šè¿‡CodingAgentçš„é¡¹ç›®ç»“æ„
            messages = [{"role": "user", "content": requirements}]
            response = await self.client.chat(messages, max_tokens=4000)
            
            # æå–Pythonä»£ç 
            python_code = self._extract_python_code(response)
            
            # ç›´æ¥ä¿å­˜åˆ°workspace_dir
            target_file = workspace_dir / "load_research_data.py"
            with open(target_file, 'w', encoding='utf-8') as f:
                f.write(python_code)
            
            result = {
                "status": "success",
                "generated_files": [str(target_file)],
                "message": "æ•°æ®åŠ è½½ä»£ç ç”ŸæˆæˆåŠŸ"
            }
            
            self.logger.info("æ•°æ®åŠ è½½ä»£ç ç”ŸæˆæˆåŠŸ")
            return result
                
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ•°æ®åŠ è½½ä»£ç æ—¶å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"ç”Ÿæˆæ•°æ®åŠ è½½ä»£ç å¤±è´¥: {str(e)}"
            }
    
    async def _test_data_loader(self, workspace_dir: Path) -> Dict[str, str]:
        """æ‰§è¡Œæ•°æ®åŠ è½½æµ‹è¯•å¹¶è¿”å›æ•°æ®ç»“æ„ä¿¡æ¯ï¼ˆæ— è®ºdebugæ¨¡å¼å¦‚ä½•éƒ½ä¼šæ‰§è¡Œï¼‰"""
        try:
            loader_file = workspace_dir / "load_research_data.py"
            if not loader_file.exists():
                return {
                    "status": "error",
                    "error": "æ•°æ®åŠ è½½æ–‡ä»¶ä¸å­˜åœ¨",
                    "message": "load_research_data.pyæ–‡ä»¶æœªæ‰¾åˆ°",
                    "data_structure_info": "",
                    "detailed_error": ""
                }
            
            self.logger.info("æ‰§è¡Œæ•°æ®åŠ è½½æµ‹è¯•ï¼ˆå°æ ·æœ¬æ¨¡å¼ï¼‰...")
            
            # æ‰§è¡ŒPythonè„šæœ¬ï¼Œç¡®ä¿æ•è·æ‰€æœ‰è¾“å‡º
            result = subprocess.run(
                ["python", "-u", "load_research_data.py"],  # -uç¡®ä¿è¾“å‡ºä¸ç¼“å†²
                cwd=str(workspace_dir),
                capture_output=True,
                text=True,
                timeout=120,  # å¢åŠ è¶…æ—¶æ—¶é—´
                env={**os.environ, "PYTHONUNBUFFERED": "1", "USE_SMALL_SAMPLE": "1"}  # æ·»åŠ å°æ ·æœ¬ç¯å¢ƒå˜é‡
            )
            
            # åˆå¹¶stdoutå’Œstderrä½œä¸ºå®Œæ•´è¾“å‡º
            full_output = ""
            if result.stdout:
                full_output += result.stdout
            if result.stderr:
                full_output += "\n=== STDERR ===\n" + result.stderr
            
            if result.returncode == 0:
                self.logger.info("æ•°æ®åŠ è½½æµ‹è¯•æˆåŠŸ")
                return {
                    "status": "success",
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "data_structure_info": result.stdout,
                    "detailed_error": "",
                    "message": "æ•°æ®åŠ è½½æµ‹è¯•å®Œæˆ"
                }
            else:
                self.logger.error(f"æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
                self.logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
                return {
                    "status": "error",
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "returncode": result.returncode,
                    "data_structure_info": full_output,  # åŒ…å«æ‰€æœ‰è¾“å‡ºä¿¡æ¯
                    "detailed_error": result.stderr,  # è¯¦ç»†é”™è¯¯ä¿¡æ¯
                    "message": "æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥"
                }
                
        except subprocess.TimeoutExpired:
            self.logger.error("æ•°æ®åŠ è½½æµ‹è¯•è¶…æ—¶")
            return {
                "status": "error",
                "error": "æ‰§è¡Œè¶…æ—¶",
                "message": "æ•°æ®åŠ è½½æµ‹è¯•è¶…æ—¶",
                "data_structure_info": "",
                "detailed_error": "æ‰§è¡Œè¶…æ—¶"
            }
        except Exception as e:
            self.logger.error(f"æ•°æ®åŠ è½½æµ‹è¯•å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {str(e)}",
                "data_structure_info": "",
                "detailed_error": str(e)
            }


    async def run_research_task(
        self,
        research_topic: str,
        research_goal: str,
        dataset_path: str,
        benchmark_name: str = "mlebench",
        dataset_name: str = "unknown",
        debug: bool = False
    ) -> Dict[str, str]:
        """
        ä¸»å…¥å£å‡½æ•°ï¼ˆLangGraphç‰ˆæœ¬ï¼‰ï¼Œæ‰§è¡Œç ”ç©¶ä»»åŠ¡

        Args:
            research_topic: ç ”ç©¶ä¸»é¢˜æè¿°
            research_goal: ç ”ç©¶ç›®æ ‡
            dataset_path: æ•°æ®é›†è·¯å¾„
            benchmark_name: benchmarkåç§°
            dataset_name: æ•°æ®é›†åç§°
            debug: æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼

        Returns:
            DictåŒ…å«ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        self.logger.info("å¼€å§‹æ‰§è¡Œç ”ç©¶ä»»åŠ¡ï¼ˆLangGraphç‰ˆæœ¬ï¼‰")
        self.logger.info(f"ç ”ç©¶ä¸»é¢˜: {research_topic}")
        self.logger.info(f"ç ”ç©¶ç›®æ ‡: {research_goal}")
        self.logger.info(f"æ•°æ®é›†è·¯å¾„: {dataset_path}")

        try:
            # æ„å»ºLangGraph
            workflow = self.build_research_graph()

            # åˆå§‹åŒ–çŠ¶æ€
            initial_state: ResearchState = {
                'research_topic': research_topic,
                'research_goal': research_goal,
                'dataset_path': dataset_path,
                'benchmark_name': benchmark_name,
                'dataset_name': dataset_name,
                'debug': debug
            }

            # è¿è¡Œworkflow
            final_state = await workflow.ainvoke(initial_state)

            # åˆ¤æ–­æœ€ç»ˆçŠ¶æ€
            status = "success"
            message = "ç ”ç©¶ä»»åŠ¡å®Œæˆ"

            # æ£€æŸ¥å…³é”®æ­¥éª¤æ˜¯å¦æˆåŠŸ
            research_test_result = final_state.get('research_test_result', {})
            full_run_result = final_state.get('full_run_result', {})
            evaluation_result = final_state.get('evaluation_result', {})

            # 1. å¦‚æœç ”ç©¶ä»£ç æµ‹è¯•å¤±è´¥ï¼ˆç»è¿‡debugåä»ç„¶å¤±è´¥ï¼‰
            if research_test_result.get('status') == 'error':
                status = "error"
                message = f"ç ”ç©¶ä»£ç æµ‹è¯•å¤±è´¥: {research_test_result.get('message', 'unknown error')}"

            # 2. å¦‚æœå®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥ï¼ˆç»è¿‡ä¼˜åŒ–åä»ç„¶å¤±è´¥ï¼‰
            elif full_run_result.get('status') == 'error':
                status = "error"
                message = f"å®Œæ•´æ•°æ®é›†è¿è¡Œå¤±è´¥: {full_run_result.get('message', 'unknown error')}"

            # 3. å¦‚æœæœ‰è¯„ä¼°ç»“æœä½†è¯„ä¼°å¤±è´¥
            elif evaluation_result and evaluation_result.get('status') == 'error':
                status = "error"
                message = f"è¯„ä¼°å¤±è´¥: {evaluation_result.get('message', 'unknown error')}"

            # 4. å¦‚æœè¯„ä¼°æˆåŠŸï¼Œä½¿ç”¨è¯„ä¼°ç»“æœçš„æ¶ˆæ¯
            elif evaluation_result and evaluation_result.get('status') == 'success':
                status = "success"
                message = evaluation_result.get('message', 'ç ”ç©¶ä»»åŠ¡å®Œæˆ')

            # æ„å»ºè¿”å›ç»“æœ
            return {
                "status": status,
                "workspace_dir": str(final_state.get('workspace_dir', '')),
                "research_topic": research_topic,
                "research_goal": research_goal,
                "dataset_path": dataset_path,
                "structure_info": final_state.get('structure_info', {}),
                "data_loader_result": final_state.get('data_loader_result', {}),
                "test_result": final_state.get('test_result', {}),
                "init_analysis_result": final_state.get('init_analysis_result', {}),
                "research_code_result": final_state.get('research_code_result', {}),
                "research_test_result": research_test_result,
                "full_run_result": full_run_result,
                "evaluation_result": evaluation_result,
                "message": message
            }

        except Exception as e:
            self.logger.error(f"ç ”ç©¶ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "message": f"ç ”ç©¶ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"
            }


# ä¾¿æ·å‡½æ•°
async def run_research_pipeline(
    research_topic: str,
    research_goal: str,
    dataset_path: str
) -> Dict[str, str]:
    """æ‰§è¡Œç ”ç©¶æµæ°´çº¿çš„ä¾¿æ·å‡½æ•°"""
    agent = InterAgent()
    return await agent.run_research_task(research_topic, research_goal, dataset_path)